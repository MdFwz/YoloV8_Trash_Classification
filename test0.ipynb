{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/gist/MdFwz/21a0fbce5821ec0bb69ada47aafaa475/test0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\""
      ],
      "metadata": {
        "id": "vZYektZAsNB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5UtMNLHMSbD",
        "outputId": "80f79ad0-05a7-4ce2-9755-26d697a59927"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmFPpm2SPUvS",
        "outputId": "b3d52ec7-f57f-4bea-918d-790733a1a12d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "config2.yaml  images  labels  labels.cache  runs\n"
          ]
        }
      ],
      "source": [
        "!ls '/content/gdrive/My Drive/Dataset5'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7H_KKnwBHt2x"
      },
      "outputs": [],
      "source": [
        "DATA_DIR = '/content/gdrive/My Drive/Dataset5'\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi -L\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLi-hgDrCry0",
        "outputId": "6deef6d7-fbd7-4a24-c417-98a97caf30c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla V100-SXM2-16GB (UUID: GPU-25b476f5-4422-cfa2-0df2-244bf66a6166)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMORmOQYIBb6",
        "outputId": "3f0da1bd-d84e-4499-f549-cb22f1fd1926"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.1.33-py3-none-any.whl (723 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/723.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.3/723.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m723.1/723.1 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.17.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Collecting thop>=0.1.1 (from ultralytics)\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.5.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.50.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m67.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m97.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m86.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, thop, ultralytics\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105 thop-0.1.1.post2209072238 ultralytics-8.1.33\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a model\n",
        "model = YOLO(\"yolov8n.yaml\") # build a new model from scratch\n",
        "\n",
        "# Use the model\n",
        "results = model.train(data=os.path.join(DATA_DIR, \"config2.yaml\"), epochs=5) # train the mode"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2Do0PhU_6-C",
        "outputId": "a7e106d0-f437-4cfb-fdd4-00986c565bb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.1.29 🚀 Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla V100-SXM2-16GB, 16151MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.yaml, data=/content/gdrive/My Drive/Dataset5/config2.yaml, epochs=5, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 755k/755k [00:00<00:00, 44.4MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overriding model.yaml nc=80 with nc=5\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    752287  ultralytics.nn.modules.head.Detect           [5, [64, 128, 256]]           \n",
            "YOLOv8n summary: 225 layers, 3011823 parameters, 3011807 gradients, 8.2 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8n.pt to 'yolov8n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6.23M/6.23M [00:00<00:00, 165MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/gdrive/My Drive/Dataset5/labels.cache... 19277 images, 14 backgrounds, 8 corrupt: 100%|██████████| 19277/19277 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/AluCan39.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0469]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/AluCan48.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.002]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/AluCan55.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.013]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/AluCan87.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0339]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/beverage_cans-181_jpg.rf.94c07f03b7c6fce17d30eb60adc0396a.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/beverage_cans-181_jpg.rf.ecaffc6ad6effedba20a8c0a75bd0418.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/beverage_cans-379_jpg.rf.d589f287ed8221437b38862ec573af15.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/beverage_cans-782_jpg.rf.640cc1151be852d5f1afdcc6cc639115.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 3990, len(boxes) = 22102. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/gdrive/My Drive/Dataset5/labels.cache... 19277 images, 14 backgrounds, 8 corrupt: 100%|██████████| 19277/19277 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/AluCan39.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0469]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/AluCan48.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.002]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/AluCan55.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.013]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/AluCan87.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0339]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/beverage_cans-181_jpg.rf.94c07f03b7c6fce17d30eb60adc0396a.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/beverage_cans-181_jpg.rf.ecaffc6ad6effedba20a8c0a75bd0418.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/beverage_cans-379_jpg.rf.d589f287ed8221437b38862ec573af15.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/beverage_cans-782_jpg.rf.640cc1151be852d5f1afdcc6cc639115.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 3990, len(boxes) = 22102. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001111, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
            "Starting training for 5 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        1/5      2.82G      2.592      3.804      3.327         17        640: 100%|██████████| 1205/1205 [23:33<00:00,  1.17s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [08:01<00:00,  1.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.541      0.151     0.0965     0.0411\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        2/5      2.72G      1.623      2.485      2.177         14        640: 100%|██████████| 1205/1205 [12:25<00:00,  1.62it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [08:29<00:00,  1.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102        0.7      0.289      0.299      0.173\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        3/5      2.64G      1.406       2.04      1.943         13        640: 100%|██████████| 1205/1205 [12:51<00:00,  1.56it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [07:49<00:00,  1.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.513      0.344      0.397      0.239\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        4/5      2.64G      1.297      1.796      1.835         17        640: 100%|██████████| 1205/1205 [12:39<00:00,  1.59it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [07:40<00:00,  1.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.567      0.479      0.496      0.316\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        5/5      2.62G      1.243      1.657      1.769         19        640: 100%|██████████| 1205/1205 [13:23<00:00,  1.50it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [07:56<00:00,  1.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.587      0.567      0.578      0.379\n",
            "\n",
            "5 epochs completed in 1.927 hours.\n",
            "Optimizer stripped from runs/detect/train/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from runs/detect/train/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating runs/detect/train/weights/best.pt...\n",
            "Ultralytics YOLOv8.1.29 🚀 Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla V100-SXM2-16GB, 16151MiB)\n",
            "YOLOv8n summary (fused): 168 layers, 3006623 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [08:06<00:00,  1.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.588      0.566      0.577      0.379\n",
            "                 paper      19269       9173      0.706      0.816      0.802       0.59\n",
            "                 metal      19269       4423      0.602      0.768      0.749      0.539\n",
            "               plastic      19269       5659      0.592      0.623      0.628       0.38\n",
            "           other trash      19269       1630      0.533      0.277      0.333      0.142\n",
            "                 phone      19269       1217      0.506      0.348      0.375      0.246\n",
            "Speed: 0.2ms preprocess, 1.3ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/runs '/content/gdrive/My Drive/Dataset5-results/train4'"
      ],
      "metadata": {
        "id": "UgiOTkEHADd_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from ultralytics import YOLO\n",
        "import torch\n",
        "\n",
        "# Load a model\n",
        "model = YOLO(\"/content/gdrive/My Drive/Dataset5-results/train4/detect/train/weights/last.pt\")   # Initialize a new model instance with the correct architecture configuration file\n",
        "\n",
        "\n",
        "# Define the number of epochs to train\n",
        "additional_epochs = 15\n",
        "\n",
        "# Use the model for training\n",
        "results = model.train(data=os.path.join(DATA_DIR, \"config2.yaml\"), epochs=additional_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYymuml0irpt",
        "outputId": "18f11e68-be89-48b3-b0ba-555c08345ea9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.1.29 🚀 Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (NVIDIA A100-SXM4-40GB, 40514MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=/content/gdrive/My Drive/Dataset5-results/train4/detect/train/weights/last.pt, data=/content/gdrive/My Drive/Dataset5/config2.yaml, epochs=15, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 755k/755k [00:00<00:00, 140MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    752287  ultralytics.nn.modules.head.Detect           [5, [64, 128, 256]]           \n",
            "YOLOv8n summary: 225 layers, 3011823 parameters, 3011807 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 355/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8n.pt to 'yolov8n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6.23M/6.23M [00:00<00:00, 66.2MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/gdrive/My Drive/Dataset5/labels.cache... 19277 images, 14 backgrounds, 8 corrupt: 100%|██████████| 19277/19277 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/AluCan39.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0469]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/AluCan48.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.002]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/AluCan55.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.013]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/AluCan87.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0339]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/beverage_cans-181_jpg.rf.94c07f03b7c6fce17d30eb60adc0396a.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/beverage_cans-181_jpg.rf.ecaffc6ad6effedba20a8c0a75bd0418.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/beverage_cans-379_jpg.rf.d589f287ed8221437b38862ec573af15.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/beverage_cans-782_jpg.rf.640cc1151be852d5f1afdcc6cc639115.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 3990, len(boxes) = 22102. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/gdrive/My Drive/Dataset5/labels.cache... 19277 images, 14 backgrounds, 8 corrupt: 100%|██████████| 19277/19277 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/AluCan39.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0469]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/AluCan48.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.002]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/AluCan55.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.013]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/AluCan87.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0339]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/beverage_cans-181_jpg.rf.94c07f03b7c6fce17d30eb60adc0396a.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/beverage_cans-181_jpg.rf.ecaffc6ad6effedba20a8c0a75bd0418.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/beverage_cans-379_jpg.rf.d589f287ed8221437b38862ec573af15.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/beverage_cans-782_jpg.rf.640cc1151be852d5f1afdcc6cc639115.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 3990, len(boxes) = 22102. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001111, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
            "Starting training for 15 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/15      2.46G      1.172      1.506      1.705         16        640: 100%|██████████| 1205/1205 [12:36<00:00,  1.59it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [01:46<00:00,  5.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.644      0.554      0.577      0.379\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/15       2.7G      1.219      1.545      1.726         17        640: 100%|██████████| 1205/1205 [02:16<00:00,  8.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [01:43<00:00,  5.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.589       0.56      0.571      0.374\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/15      2.75G      1.204      1.508      1.704          7        640: 100%|██████████| 1205/1205 [02:13<00:00,  9.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [01:44<00:00,  5.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.634      0.582      0.593      0.386\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/15      3.13G      1.179       1.44      1.671         11        640: 100%|██████████| 1205/1205 [02:13<00:00,  9.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [01:44<00:00,  5.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.663      0.599      0.624      0.414\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/15      2.68G      1.156       1.39      1.645         10        640: 100%|██████████| 1205/1205 [02:13<00:00,  9.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [01:44<00:00,  5.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.719      0.624      0.673      0.447\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/15      2.91G      1.108      1.167      1.666          5        640: 100%|██████████| 1205/1205 [02:13<00:00,  9.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [01:43<00:00,  5.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102        0.7       0.66      0.693      0.461\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/15      2.75G      1.056      1.054       1.61          5        640: 100%|██████████| 1205/1205 [02:11<00:00,  9.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [01:43<00:00,  5.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.758      0.693      0.738      0.509\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/15      2.72G      1.021     0.9829      1.573          5        640: 100%|██████████| 1205/1205 [02:11<00:00,  9.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [01:43<00:00,  5.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.804      0.687      0.756       0.53\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/15      2.73G     0.9883     0.9349       1.54          5        640: 100%|██████████| 1205/1205 [02:11<00:00,  9.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [01:42<00:00,  5.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.805      0.718       0.78      0.554\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/15      2.96G     0.9652     0.8831      1.514          5        640: 100%|██████████| 1205/1205 [02:11<00:00,  9.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [01:43<00:00,  5.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.827       0.74      0.802      0.574\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      11/15      2.71G     0.9368     0.8442      1.484        123        640: 100%|██████████| 1205/1205 [02:10<00:00,  9.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [01:42<00:00,  5.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.832      0.746      0.814      0.587\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      12/15      2.65G     0.9102     0.8074      1.459          5        640: 100%|██████████| 1205/1205 [02:11<00:00,  9.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [01:42<00:00,  5.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102       0.83      0.761      0.831      0.607\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      13/15      2.67G     0.8877     0.7641      1.434          6        640: 100%|██████████| 1205/1205 [02:11<00:00,  9.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [01:43<00:00,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.854      0.766      0.838      0.618\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      14/15      2.96G     0.8692     0.7392      1.418          5        640: 100%|██████████| 1205/1205 [02:11<00:00,  9.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [01:43<00:00,  5.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.855      0.774      0.849      0.633\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      15/15      2.73G     0.8507     0.7112      1.402          5        640: 100%|██████████| 1205/1205 [02:11<00:00,  9.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [01:43<00:00,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.869      0.779      0.858      0.641\n",
            "\n",
            "15 epochs completed in 1.164 hours.\n",
            "Optimizer stripped from runs/detect/train/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from runs/detect/train/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating runs/detect/train/weights/best.pt...\n",
            "Ultralytics YOLOv8.1.29 🚀 Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (NVIDIA A100-SXM4-40GB, 40514MiB)\n",
            "YOLOv8n summary (fused): 168 layers, 3006623 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [01:46<00:00,  5.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102       0.87      0.778      0.858      0.641\n",
            "                 paper      19269       9173      0.908      0.887      0.941      0.789\n",
            "                 metal      19269       4423      0.906      0.883      0.941      0.745\n",
            "               plastic      19269       5659       0.88      0.752      0.835      0.575\n",
            "           other trash      19269       1630      0.841      0.653      0.778      0.499\n",
            "                 phone      19269       1217      0.817      0.715      0.794      0.599\n",
            "Speed: 0.1ms preprocess, 0.6ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/runs '/content/gdrive/My Drive/Dataset5-results/train4-2'"
      ],
      "metadata": {
        "id": "ZRiC632tjHaV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from ultralytics import YOLO\n",
        "import torch\n",
        "\n",
        "# Load a model\n",
        "model = YOLO(\"/content/gdrive/My Drive/Dataset5-results/train4-2/runs/detect/train/weights/last.pt\")   # Initialize a new model instance with the correct architecture configuration file\n",
        "\n",
        "\n",
        "# Define the number of epochs to train\n",
        "additional_epochs = 20\n",
        "\n",
        "# Use the model for training\n",
        "results = model.train(data=os.path.join(DATA_DIR, \"config2.yaml\"), epochs=additional_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtZA487ise_F",
        "outputId": "183f298d-ab80-4c57-9790-4d9df79b59f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.1.33 🚀 Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (NVIDIA A100-SXM4-40GB, 40514MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=/content/gdrive/My Drive/Dataset5-results/train4-2/runs/detect/train/weights/last.pt, data=/content/gdrive/My Drive/Dataset5/config2.yaml, epochs=20, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 755k/755k [00:00<00:00, 68.0MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    752287  ultralytics.nn.modules.head.Detect           [5, [64, 128, 256]]           \n",
            "YOLOv8n summary: 225 layers, 3011823 parameters, 3011807 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 355/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8n.pt to 'yolov8n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6.23M/6.23M [00:00<00:00, 308MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/gdrive/My Drive/Dataset5/labels.cache... 19277 images, 14 backgrounds, 8 corrupt: 100%|██████████| 19277/19277 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/AluCan39.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0469]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/AluCan48.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.002]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/AluCan55.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.013]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/AluCan87.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0339]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/beverage_cans-181_jpg.rf.94c07f03b7c6fce17d30eb60adc0396a.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/beverage_cans-181_jpg.rf.ecaffc6ad6effedba20a8c0a75bd0418.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/beverage_cans-379_jpg.rf.d589f287ed8221437b38862ec573af15.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/beverage_cans-782_jpg.rf.640cc1151be852d5f1afdcc6cc639115.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 3990, len(boxes) = 22102. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/gdrive/My Drive/Dataset5/labels.cache... 19277 images, 14 backgrounds, 8 corrupt: 100%|██████████| 19277/19277 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/AluCan39.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0469]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/AluCan48.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.002]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/AluCan55.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.013]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/AluCan87.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0339]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/beverage_cans-181_jpg.rf.94c07f03b7c6fce17d30eb60adc0396a.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/beverage_cans-181_jpg.rf.ecaffc6ad6effedba20a8c0a75bd0418.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/beverage_cans-379_jpg.rf.d589f287ed8221437b38862ec573af15.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/beverage_cans-782_jpg.rf.640cc1151be852d5f1afdcc6cc639115.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 3990, len(boxes) = 22102. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001111, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/20      2.86G      1.049      1.194       1.53         13        640: 100%|██████████| 1205/1205 [12:01<00:00,  1.67it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [01:46<00:00,  5.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.833      0.741      0.816       0.59\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/20      2.49G      1.037      1.143      1.518          9        640: 100%|██████████| 1205/1205 [02:17<00:00,  8.74it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [01:43<00:00,  5.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.793      0.711      0.777      0.546\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/20       2.5G      1.042      1.151      1.516         10        640: 100%|██████████| 1205/1205 [02:15<00:00,  8.89it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [01:43<00:00,  5.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.806      0.721      0.783      0.544\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/20      2.75G      1.048      1.157      1.519         16        640: 100%|██████████| 1205/1205 [02:14<00:00,  8.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [01:43<00:00,  5.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.797      0.707      0.772      0.545\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/20      2.49G      1.034      1.135      1.504         10        640: 100%|██████████| 1205/1205 [02:13<00:00,  9.03it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [01:42<00:00,  5.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.816       0.72      0.789      0.557\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/20      2.73G      1.023      1.097      1.489         13        640: 100%|██████████| 1205/1205 [02:13<00:00,  9.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [01:42<00:00,  5.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.825      0.735      0.801      0.573\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/20      2.65G      1.003      1.069      1.476          9        640: 100%|██████████| 1205/1205 [02:13<00:00,  9.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [01:43<00:00,  5.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102       0.81      0.727      0.794      0.568\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/20      2.93G     0.9914      1.052      1.462         14        640: 100%|██████████| 1205/1205 [02:13<00:00,  9.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [01:42<00:00,  5.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.833      0.745      0.814      0.585\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/20      2.87G     0.9835      1.032      1.453         15        640: 100%|██████████| 1205/1205 [02:13<00:00,  9.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [01:42<00:00,  5.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102       0.84      0.753      0.816      0.593\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/20      2.64G     0.9608      1.002      1.435         15        640: 100%|██████████| 1205/1205 [02:13<00:00,  9.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [01:43<00:00,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.818      0.748      0.815        0.6\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      11/20      2.73G     0.9088     0.7847       1.44        123        640: 100%|██████████| 1205/1205 [02:14<00:00,  8.99it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [01:42<00:00,  5.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.848      0.769      0.847      0.618\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      12/20      2.74G     0.8849     0.7357      1.413          5        640: 100%|██████████| 1205/1205 [02:11<00:00,  9.13it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [01:43<00:00,  5.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.846      0.789      0.854      0.633\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      13/20      2.73G     0.8634     0.7063      1.394          6        640: 100%|██████████| 1205/1205 [02:12<00:00,  9.10it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [01:42<00:00,  5.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102       0.87      0.782      0.865      0.644\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      14/20      2.72G     0.8471     0.6796      1.379          5        640: 100%|██████████| 1205/1205 [02:11<00:00,  9.13it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [01:43<00:00,  5.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.881      0.787      0.868      0.654\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      15/20      2.73G     0.8316     0.6611      1.361          5        640: 100%|██████████| 1205/1205 [02:11<00:00,  9.14it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [01:42<00:00,  5.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102       0.87      0.806      0.878      0.667\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      16/20      2.73G     0.8184     0.6392      1.348          5        640: 100%|██████████| 1205/1205 [02:11<00:00,  9.14it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [01:43<00:00,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.881      0.807      0.883      0.676\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      17/20      2.87G     0.8007     0.6234      1.334          5        640: 100%|██████████| 1205/1205 [02:12<00:00,  9.09it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [01:43<00:00,  5.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.889      0.816      0.893      0.687\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      18/20      2.72G     0.7928     0.6033      1.326          6        640: 100%|██████████| 1205/1205 [02:12<00:00,  9.11it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [01:43<00:00,  5.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.894      0.817      0.895      0.691\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      19/20      2.89G     0.7774     0.5845       1.31          6        640: 100%|██████████| 1205/1205 [02:12<00:00,  9.10it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [01:42<00:00,  5.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.896      0.824        0.9      0.698\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      20/20      2.73G     0.7644      0.571      1.299          5        640: 100%|██████████| 1205/1205 [02:11<00:00,  9.13it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [01:43<00:00,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.902      0.828      0.903      0.703\n",
            "\n",
            "20 epochs completed in 1.485 hours.\n",
            "Optimizer stripped from runs/detect/train/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from runs/detect/train/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating runs/detect/train/weights/best.pt...\n",
            "Ultralytics YOLOv8.1.33 🚀 Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (NVIDIA A100-SXM4-40GB, 40514MiB)\n",
            "YOLOv8n summary (fused): 168 layers, 3006623 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [01:46<00:00,  5.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.901      0.828      0.903      0.703\n",
            "                 paper      19269       9173      0.942      0.903      0.961      0.831\n",
            "                 metal      19269       4423       0.94      0.929      0.968      0.793\n",
            "               plastic      19269       5659      0.912      0.784      0.871       0.63\n",
            "           other trash      19269       1630      0.873      0.736      0.854       0.59\n",
            "                 phone      19269       1217      0.839      0.789      0.857      0.672\n",
            "Speed: 0.1ms preprocess, 0.6ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/runs '/content/gdrive/My Drive/Dataset5-results/train4-3'"
      ],
      "metadata": {
        "id": "RPrv4GyLzaUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from ultralytics import YOLO\n",
        "import torch\n",
        "\n",
        "# Load a model\n",
        "model = YOLO(\"/content/gdrive/My Drive/Dataset5-results/train4-3/detect/train/weights/last.pt\")   # Initialize a new model instance with the correct architecture configuration file\n",
        "\n",
        "\n",
        "# Define the number of epochs to train\n",
        "additional_epochs = 12\n",
        "\n",
        "# Use the model for training\n",
        "results = model.train(data=os.path.join(DATA_DIR, \"config2.yaml\"), epochs=additional_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNi5FaES1JLR",
        "outputId": "b82b4cc5-8d1c-466e-d7f1-57dba5c6e4b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.1.33 🚀 Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (NVIDIA A100-SXM4-40GB, 40514MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=/content/gdrive/My Drive/Dataset5-results/train4-3/detect/train/weights/last.pt, data=/content/gdrive/My Drive/Dataset5/config2.yaml, epochs=12, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train2\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    752287  ultralytics.nn.modules.head.Detect           [5, [64, 128, 256]]           \n",
            "YOLOv8n summary: 225 layers, 3011823 parameters, 3011807 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 355/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train2', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/gdrive/My Drive/Dataset5/labels.cache... 19277 images, 14 backgrounds, 8 corrupt: 100%|██████████| 19277/19277 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/AluCan39.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0469]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/AluCan48.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.002]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/AluCan55.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.013]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/AluCan87.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0339]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/beverage_cans-181_jpg.rf.94c07f03b7c6fce17d30eb60adc0396a.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/beverage_cans-181_jpg.rf.ecaffc6ad6effedba20a8c0a75bd0418.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/beverage_cans-379_jpg.rf.d589f287ed8221437b38862ec573af15.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/beverage_cans-782_jpg.rf.640cc1151be852d5f1afdcc6cc639115.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 3990, len(boxes) = 22102. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/gdrive/My Drive/Dataset5/labels.cache... 19277 images, 14 backgrounds, 8 corrupt: 100%|██████████| 19277/19277 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/AluCan39.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0469]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/AluCan48.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.002]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/AluCan55.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.013]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/AluCan87.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0339]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/beverage_cans-181_jpg.rf.94c07f03b7c6fce17d30eb60adc0396a.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/beverage_cans-181_jpg.rf.ecaffc6ad6effedba20a8c0a75bd0418.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/beverage_cans-379_jpg.rf.d589f287ed8221437b38862ec573af15.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/beverage_cans-782_jpg.rf.640cc1151be852d5f1afdcc6cc639115.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 3990, len(boxes) = 22102. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/detect/train2/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001111, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train2\u001b[0m\n",
            "Starting training for 12 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/12      2.93G     0.9241     0.9464      1.402         13        640: 100%|██████████| 1205/1205 [02:55<00:00,  6.87it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [01:43<00:00,  5.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.874      0.802      0.876       0.66\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/12       2.5G     0.9218      0.927      1.396          9        640: 100%|██████████| 1205/1205 [02:20<00:00,  8.58it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [01:43<00:00,  5.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.862      0.773      0.852      0.634\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/12      2.74G     0.8746     0.7223      1.395          5        640: 100%|██████████| 1205/1205 [02:17<00:00,  8.78it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [01:43<00:00,  5.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.852      0.742      0.828      0.612\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/12      2.74G     0.8722      0.718      1.386          5        640: 100%|██████████| 1205/1205 [02:13<00:00,  9.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [01:44<00:00,  5.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.841      0.773       0.85      0.623\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/12      2.91G     0.8694     0.7072      1.385          5        640: 100%|██████████| 1205/1205 [02:13<00:00,  9.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [01:42<00:00,  5.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.867      0.776      0.857      0.636\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/12      2.91G     0.8517     0.6933      1.368          5        640: 100%|██████████| 1205/1205 [02:13<00:00,  9.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [01:43<00:00,  5.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.878      0.779      0.863      0.651\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/12       2.7G     0.8332     0.6579      1.352          5        640: 100%|██████████| 1205/1205 [02:13<00:00,  9.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [01:43<00:00,  5.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.882      0.805      0.882      0.669\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/12      2.74G     0.8135     0.6307      1.334          5        640: 100%|██████████| 1205/1205 [02:13<00:00,  9.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [01:43<00:00,  5.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.881      0.814      0.888      0.678\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/12      2.74G     0.7986     0.6071       1.32          5        640: 100%|██████████| 1205/1205 [02:13<00:00,  9.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [01:43<00:00,  5.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.892      0.815      0.895      0.688\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/12      2.73G     0.7787     0.5754      1.304          5        640: 100%|██████████| 1205/1205 [02:12<00:00,  9.08it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [01:43<00:00,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.897      0.828      0.904      0.703\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      11/12      2.74G     0.7598      0.562      1.285        123        640: 100%|██████████| 1205/1205 [02:12<00:00,  9.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [01:43<00:00,  5.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.895      0.836      0.909      0.711\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      12/12      2.74G     0.7429     0.5319      1.272          5        640: 100%|██████████| 1205/1205 [02:13<00:00,  9.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [01:43<00:00,  5.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.906      0.841      0.917      0.721\n",
            "\n",
            "12 epochs completed in 0.809 hours.\n",
            "Optimizer stripped from runs/detect/train2/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from runs/detect/train2/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating runs/detect/train2/weights/best.pt...\n",
            "Ultralytics YOLOv8.1.33 🚀 Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (NVIDIA A100-SXM4-40GB, 40514MiB)\n",
            "YOLOv8n summary (fused): 168 layers, 3006623 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [01:47<00:00,  5.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.905      0.842      0.917      0.721\n",
            "                 paper      19269       9173      0.947      0.919       0.97      0.843\n",
            "                 metal      19269       4423      0.938      0.943      0.977      0.802\n",
            "               plastic      19269       5659      0.889        0.8       0.88      0.644\n",
            "           other trash      19269       1630      0.868      0.751      0.871      0.621\n",
            "                 phone      19269       1217      0.885      0.796      0.887      0.698\n",
            "Speed: 0.1ms preprocess, 0.6ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train2\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/runs '/content/gdrive/My Drive/Dataset5-results/train4-3'"
      ],
      "metadata": {
        "id": "EA-S-XsACL8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a model\n",
        "model = YOLO(\"yolov8x.yaml\") # build a new model from scratch\n",
        "\n",
        "# Use the model\n",
        "results = model.train(data=os.path.join(DATA_DIR, \"config2.yaml\"), epochs=15) # train the mode"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bv_CPIRtf_H",
        "outputId": "66ec2b54-6c7f-4c6e-f39a-033f5465c3a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.1.27 🚀 Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (NVIDIA A100-SXM4-40GB, 40514MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8x.yaml, data=/content/gdrive/My Drive/Dataset5/config2.yaml, epochs=15, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 755k/755k [00:00<00:00, 27.6MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overriding model.yaml nc=80 with nc=5\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      2320  ultralytics.nn.modules.conv.Conv             [3, 80, 3, 2]                 \n",
            "  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n",
            "  2                  -1  3    436800  ultralytics.nn.modules.block.C2f             [160, 160, 3, True]           \n",
            "  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n",
            "  4                  -1  6   3281920  ultralytics.nn.modules.block.C2f             [320, 320, 6, True]           \n",
            "  5                  -1  1   1844480  ultralytics.nn.modules.conv.Conv             [320, 640, 3, 2]              \n",
            "  6                  -1  6  13117440  ultralytics.nn.modules.block.C2f             [640, 640, 6, True]           \n",
            "  7                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
            "  8                  -1  3   6969600  ultralytics.nn.modules.block.C2f             [640, 640, 3, True]           \n",
            "  9                  -1  1   1025920  ultralytics.nn.modules.block.SPPF            [640, 640, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  3   1948800  ultralytics.nn.modules.block.C2f             [960, 320, 3]                 \n",
            " 16                  -1  1    922240  ultralytics.nn.modules.conv.Conv             [320, 320, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  3   7174400  ultralytics.nn.modules.block.C2f             [960, 640, 3]                 \n",
            " 19                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
            " 22        [15, 18, 21]  1   8722783  ultralytics.nn.modules.head.Detect           [5, [320, 640, 640]]          \n",
            "YOLOv8x summary: 365 layers, 68157423 parameters, 68157407 gradients, 258.1 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8n.pt to 'yolov8n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6.23M/6.23M [00:00<00:00, 107MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/gdrive/My Drive/Dataset5/labels.cache... 19277 images, 14 backgrounds, 8 corrupt: 100%|██████████| 19277/19277 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/AluCan39.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0469]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/AluCan48.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.002]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/AluCan55.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.013]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/AluCan87.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0339]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/beverage_cans-181_jpg.rf.94c07f03b7c6fce17d30eb60adc0396a.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/beverage_cans-181_jpg.rf.ecaffc6ad6effedba20a8c0a75bd0418.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/beverage_cans-379_jpg.rf.d589f287ed8221437b38862ec573af15.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/beverage_cans-782_jpg.rf.640cc1151be852d5f1afdcc6cc639115.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 3990, len(boxes) = 22102. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/gdrive/My Drive/Dataset5/labels.cache... 19277 images, 14 backgrounds, 8 corrupt: 100%|██████████| 19277/19277 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/AluCan39.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0469]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/AluCan48.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.002]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/AluCan55.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.013]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/AluCan87.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0339]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/beverage_cans-181_jpg.rf.94c07f03b7c6fce17d30eb60adc0396a.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/beverage_cans-181_jpg.rf.ecaffc6ad6effedba20a8c0a75bd0418.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/beverage_cans-379_jpg.rf.d589f287ed8221437b38862ec573af15.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/beverage_cans-782_jpg.rf.640cc1151be852d5f1afdcc6cc639115.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 3990, len(boxes) = 22102. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001111, momentum=0.9) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
            "Starting training for 15 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/15      13.3G      2.209      3.254      2.897         16        640: 100%|██████████| 1205/1205 [16:41<00:00,  1.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [02:24<00:00,  4.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.604      0.249      0.198      0.113\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/15      13.1G      1.477      2.197      2.032         17        640: 100%|██████████| 1205/1205 [04:37<00:00,  4.35it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [02:20<00:00,  4.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.751      0.322      0.337      0.211\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/15        13G      1.306      1.862      1.862          7        640: 100%|██████████| 1205/1205 [04:29<00:00,  4.46it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [02:19<00:00,  4.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.833      0.363      0.445      0.286\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/15        13G      1.222      1.639      1.768         11        640: 100%|██████████| 1205/1205 [04:27<00:00,  4.50it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [02:18<00:00,  4.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.697      0.487      0.526      0.341\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/15        13G      1.165      1.491      1.708         10        640: 100%|██████████| 1205/1205 [04:29<00:00,  4.48it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [02:18<00:00,  4.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.563       0.57      0.576      0.382\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/15        13G      1.107       1.25      1.726          5        640: 100%|██████████| 1205/1205 [04:32<00:00,  4.42it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [02:19<00:00,  4.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.655      0.604      0.637      0.442\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/15      13.1G      1.046      1.105      1.654          5        640: 100%|██████████| 1205/1205 [04:28<00:00,  4.49it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [02:19<00:00,  4.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.711      0.629      0.675      0.467\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/15      13.1G     0.9991      1.003      1.607          5        640: 100%|██████████| 1205/1205 [04:27<00:00,  4.50it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [02:18<00:00,  4.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.767      0.676      0.733      0.524\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/15        13G     0.9673     0.9447      1.573          5        640: 100%|██████████| 1205/1205 [04:29<00:00,  4.48it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [02:18<00:00,  4.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.775      0.704      0.758      0.538\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/15        13G     0.9412     0.8893      1.544          5        640: 100%|██████████| 1205/1205 [04:28<00:00,  4.49it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [02:18<00:00,  4.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.807      0.713      0.785      0.566\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      11/15      13.1G     0.9114     0.8376      1.513        123        640: 100%|██████████| 1205/1205 [04:27<00:00,  4.50it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [02:18<00:00,  4.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.822      0.732      0.804      0.588\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      12/15        13G     0.8827     0.7854      1.479          5        640: 100%|██████████| 1205/1205 [04:27<00:00,  4.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [02:18<00:00,  4.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.834      0.747      0.819      0.607\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      13/15        13G     0.8628     0.7405      1.457          6        640: 100%|██████████| 1205/1205 [04:29<00:00,  4.48it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [02:19<00:00,  4.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.861       0.75      0.836      0.624\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      14/15        13G      0.834      0.701      1.432          5        640: 100%|██████████| 1205/1205 [04:29<00:00,  4.47it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [02:19<00:00,  4.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.859      0.764      0.845      0.637\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      15/15      13.1G     0.8096     0.6642      1.411          5        640: 100%|██████████| 1205/1205 [04:28<00:00,  4.49it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [02:18<00:00,  4.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.871      0.778       0.86      0.655\n",
            "\n",
            "15 epochs completed in 1.930 hours.\n",
            "Optimizer stripped from runs/detect/train/weights/last.pt, 136.7MB\n",
            "Optimizer stripped from runs/detect/train/weights/best.pt, 136.7MB\n",
            "\n",
            "Validating runs/detect/train/weights/best.pt...\n",
            "Ultralytics YOLOv8.1.27 🚀 Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (NVIDIA A100-SXM4-40GB, 40514MiB)\n",
            "YOLOv8x summary (fused): 268 layers, 68128383 parameters, 0 gradients, 257.4 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [02:22<00:00,  4.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.871      0.778       0.86      0.655\n",
            "                 paper      19269       9173      0.908      0.888      0.944      0.805\n",
            "                 metal      19269       4423       0.92      0.884      0.949      0.763\n",
            "               plastic      19269       5659      0.882      0.771      0.845      0.596\n",
            "           other trash      19269       1630      0.828       0.63      0.769      0.503\n",
            "                 phone      19269       1217      0.818      0.715      0.796      0.607\n",
            "Speed: 0.1ms preprocess, 3.2ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/runs '/content/gdrive/My Drive/Dataset5'"
      ],
      "metadata": {
        "id": "ShjbaMuoto1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from ultralytics import YOLO\n",
        "import torch\n",
        "\n",
        "# Load a model\n",
        "model = YOLO(\"/content/gdrive/My Drive/Dataset5/runs/detect/train/weights/last.pt\")   # Initialize a new model instance with the correct architecture configuration file\n",
        "\n",
        "\n",
        "# Define the number of epochs to train\n",
        "additional_epochs = 10\n",
        "\n",
        "# Use the model for training\n",
        "results = model.train(data=os.path.join(DATA_DIR, \"config2.yaml\"), epochs=additional_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkoK8L72vyhv",
        "outputId": "ea0653fe-8a05-4043-f8a7-9b5091f670a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.1.27 🚀 Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (NVIDIA A100-SXM4-40GB, 40514MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=/content/gdrive/My Drive/Dataset5/runs/detect/train/weights/last.pt, data=/content/gdrive/My Drive/Dataset5/config2.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train2\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      2320  ultralytics.nn.modules.conv.Conv             [3, 80, 3, 2]                 \n",
            "  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n",
            "  2                  -1  3    436800  ultralytics.nn.modules.block.C2f             [160, 160, 3, True]           \n",
            "  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n",
            "  4                  -1  6   3281920  ultralytics.nn.modules.block.C2f             [320, 320, 6, True]           \n",
            "  5                  -1  1   1844480  ultralytics.nn.modules.conv.Conv             [320, 640, 3, 2]              \n",
            "  6                  -1  6  13117440  ultralytics.nn.modules.block.C2f             [640, 640, 6, True]           \n",
            "  7                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
            "  8                  -1  3   6969600  ultralytics.nn.modules.block.C2f             [640, 640, 3, True]           \n",
            "  9                  -1  1   1025920  ultralytics.nn.modules.block.SPPF            [640, 640, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  3   1948800  ultralytics.nn.modules.block.C2f             [960, 320, 3]                 \n",
            " 16                  -1  1    922240  ultralytics.nn.modules.conv.Conv             [320, 320, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  3   7174400  ultralytics.nn.modules.block.C2f             [960, 640, 3]                 \n",
            " 19                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
            " 22        [15, 18, 21]  1   8722783  ultralytics.nn.modules.head.Detect           [5, [320, 640, 640]]          \n",
            "YOLOv8x summary: 365 layers, 68157423 parameters, 68157407 gradients, 258.1 GFLOPs\n",
            "\n",
            "Transferred 595/595 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train2', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/gdrive/My Drive/Dataset5/labels.cache... 19277 images, 14 backgrounds, 8 corrupt: 100%|██████████| 19277/19277 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/AluCan39.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0469]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/AluCan48.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.002]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/AluCan55.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.013]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/AluCan87.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0339]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/beverage_cans-181_jpg.rf.94c07f03b7c6fce17d30eb60adc0396a.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/beverage_cans-181_jpg.rf.ecaffc6ad6effedba20a8c0a75bd0418.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/beverage_cans-379_jpg.rf.d589f287ed8221437b38862ec573af15.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/beverage_cans-782_jpg.rf.640cc1151be852d5f1afdcc6cc639115.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 3990, len(boxes) = 22102. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/gdrive/My Drive/Dataset5/labels.cache... 19277 images, 14 backgrounds, 8 corrupt: 100%|██████████| 19277/19277 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/AluCan39.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0469]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/AluCan48.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.002]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/AluCan55.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.013]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/AluCan87.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0339]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/beverage_cans-181_jpg.rf.94c07f03b7c6fce17d30eb60adc0396a.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/beverage_cans-181_jpg.rf.ecaffc6ad6effedba20a8c0a75bd0418.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/beverage_cans-379_jpg.rf.d589f287ed8221437b38862ec573af15.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/beverage_cans-782_jpg.rf.640cc1151be852d5f1afdcc6cc639115.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 3990, len(boxes) = 22102. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "Plotting labels to runs/detect/train2/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001111, momentum=0.9) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train2\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/10      13.3G     0.8295     0.6849      1.426          5        640: 100%|██████████| 1205/1205 [05:27<00:00,  3.68it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [02:17<00:00,  4.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.847      0.731      0.817      0.604\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/10      13.1G     0.8953     0.7863      1.484          5        640: 100%|██████████| 1205/1205 [04:36<00:00,  4.35it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [02:18<00:00,  4.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.795      0.717       0.79      0.568\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/10      13.1G     0.9149     0.8268      1.506          5        640: 100%|██████████| 1205/1205 [04:29<00:00,  4.47it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [02:17<00:00,  4.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.809      0.728      0.802      0.581\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/10      13.1G     0.9064     0.8049      1.492          5        640: 100%|██████████| 1205/1205 [04:27<00:00,  4.50it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [02:18<00:00,  4.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.818      0.737      0.812      0.589\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/10      13.1G     0.8921     0.7819      1.479          5        640: 100%|██████████| 1205/1205 [04:27<00:00,  4.50it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [02:18<00:00,  4.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.832      0.738      0.821      0.603\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/10      13.1G     0.8691     0.7492      1.461          5        640: 100%|██████████| 1205/1205 [04:27<00:00,  4.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [02:19<00:00,  4.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.833      0.762       0.83      0.612\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/10      13.1G     0.8411     0.6913       1.43          5        640: 100%|██████████| 1205/1205 [04:28<00:00,  4.49it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [02:19<00:00,  4.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.873      0.774      0.859      0.642\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/10      13.1G     0.8155     0.6589      1.403          5        640: 100%|██████████| 1205/1205 [04:28<00:00,  4.49it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [02:18<00:00,  4.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.877      0.786      0.871      0.662\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/10      13.1G     0.7904     0.6153      1.379          5        640: 100%|██████████| 1205/1205 [04:28<00:00,  4.49it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [02:17<00:00,  4.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.874      0.795       0.88      0.674\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/10      13.1G      0.762     0.5773      1.349          5        640: 100%|██████████| 1205/1205 [04:27<00:00,  4.50it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [02:18<00:00,  4.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.895      0.807      0.894      0.697\n",
            "\n",
            "10 epochs completed in 1.162 hours.\n",
            "Optimizer stripped from runs/detect/train2/weights/last.pt, 136.7MB\n",
            "Optimizer stripped from runs/detect/train2/weights/best.pt, 136.7MB\n",
            "\n",
            "Validating runs/detect/train2/weights/best.pt...\n",
            "Ultralytics YOLOv8.1.27 🚀 Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (NVIDIA A100-SXM4-40GB, 40514MiB)\n",
            "YOLOv8x summary (fused): 268 layers, 68128383 parameters, 0 gradients, 257.4 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [02:22<00:00,  4.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.895      0.807      0.894      0.697\n",
            "                 paper      19269       9173       0.94      0.894      0.959      0.827\n",
            "                 metal      19269       4423      0.923      0.934       0.97      0.795\n",
            "               plastic      19269       5659      0.898      0.786      0.868      0.631\n",
            "           other trash      19269       1630      0.901      0.643      0.829      0.572\n",
            "                 phone      19269       1217      0.814      0.778      0.843      0.659\n",
            "Speed: 0.1ms preprocess, 3.2ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train2\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/runs '/content/gdrive/My Drive/Dataset5'"
      ],
      "metadata": {
        "id": "lRg1ltRFBfCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from ultralytics import YOLO\n",
        "import torch\n",
        "\n",
        "# Load a model\n",
        "model = YOLO(\"/content/gdrive/My Drive/Dataset5/runs/detect/train2/weights/last.pt\")   # Initialize a new model instance with the correct architecture configuration file\n",
        "\n",
        "\n",
        "# Define the number of epochs to train\n",
        "additional_epochs = 15\n",
        "\n",
        "# Use the model for training\n",
        "results = model.train(data=os.path.join(DATA_DIR, \"config2.yaml\"), epochs=additional_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_bezbpvnCED",
        "outputId": "76fcc872-12c3-46b7-afda-5dd8b1db1ed2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.1.29 🚀 Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (NVIDIA A100-SXM4-40GB, 40514MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=/content/gdrive/My Drive/Dataset5/runs/detect/train2/weights/last.pt, data=/content/gdrive/My Drive/Dataset5/config2.yaml, epochs=15, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 755k/755k [00:00<00:00, 23.0MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      2320  ultralytics.nn.modules.conv.Conv             [3, 80, 3, 2]                 \n",
            "  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n",
            "  2                  -1  3    436800  ultralytics.nn.modules.block.C2f             [160, 160, 3, True]           \n",
            "  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n",
            "  4                  -1  6   3281920  ultralytics.nn.modules.block.C2f             [320, 320, 6, True]           \n",
            "  5                  -1  1   1844480  ultralytics.nn.modules.conv.Conv             [320, 640, 3, 2]              \n",
            "  6                  -1  6  13117440  ultralytics.nn.modules.block.C2f             [640, 640, 6, True]           \n",
            "  7                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
            "  8                  -1  3   6969600  ultralytics.nn.modules.block.C2f             [640, 640, 3, True]           \n",
            "  9                  -1  1   1025920  ultralytics.nn.modules.block.SPPF            [640, 640, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  3   1948800  ultralytics.nn.modules.block.C2f             [960, 320, 3]                 \n",
            " 16                  -1  1    922240  ultralytics.nn.modules.conv.Conv             [320, 320, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  3   7174400  ultralytics.nn.modules.block.C2f             [960, 640, 3]                 \n",
            " 19                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
            " 22        [15, 18, 21]  1   8722783  ultralytics.nn.modules.head.Detect           [5, [320, 640, 640]]          \n",
            "YOLOv8x summary: 365 layers, 68157423 parameters, 68157407 gradients, 258.1 GFLOPs\n",
            "\n",
            "Transferred 595/595 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8n.pt to 'yolov8n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6.23M/6.23M [00:00<00:00, 113MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/gdrive/My Drive/Dataset5/labels.cache... 19277 images, 14 backgrounds, 8 corrupt: 100%|██████████| 19277/19277 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/AluCan39.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0469]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/AluCan48.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.002]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/AluCan55.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.013]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/AluCan87.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0339]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/beverage_cans-181_jpg.rf.94c07f03b7c6fce17d30eb60adc0396a.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/beverage_cans-181_jpg.rf.ecaffc6ad6effedba20a8c0a75bd0418.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/beverage_cans-379_jpg.rf.d589f287ed8221437b38862ec573af15.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/beverage_cans-782_jpg.rf.640cc1151be852d5f1afdcc6cc639115.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 3990, len(boxes) = 22102. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/gdrive/My Drive/Dataset5/labels.cache... 19277 images, 14 backgrounds, 8 corrupt: 100%|██████████| 19277/19277 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/AluCan39.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0469]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/AluCan48.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.002]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/AluCan55.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.013]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/AluCan87.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0339]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/beverage_cans-181_jpg.rf.94c07f03b7c6fce17d30eb60adc0396a.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/beverage_cans-181_jpg.rf.ecaffc6ad6effedba20a8c0a75bd0418.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/beverage_cans-379_jpg.rf.d589f287ed8221437b38862ec573af15.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/beverage_cans-782_jpg.rf.640cc1151be852d5f1afdcc6cc639115.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 3990, len(boxes) = 22102. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001111, momentum=0.9) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
            "Starting training for 15 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/15      13.3G     0.9787      1.091      1.521         16        640: 100%|██████████| 1205/1205 [14:43<00:00,  1.36it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [02:21<00:00,  4.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102       0.87      0.777      0.857      0.646\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/15        13G     0.9594      1.001      1.499         17        640: 100%|██████████| 1205/1205 [04:35<00:00,  4.38it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [02:18<00:00,  4.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.837      0.749      0.828      0.615\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/15        13G     0.9502     0.9939      1.486          7        640: 100%|██████████| 1205/1205 [04:29<00:00,  4.47it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [02:19<00:00,  4.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.844      0.757      0.835      0.619\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/15        13G     0.9456     0.9818      1.476         11        640: 100%|██████████| 1205/1205 [04:27<00:00,  4.50it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [02:18<00:00,  4.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.813       0.72      0.803      0.585\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/15        13G      0.939     0.9666      1.474         10        640: 100%|██████████| 1205/1205 [04:27<00:00,  4.50it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [02:18<00:00,  4.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.847      0.757      0.843      0.625\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/15        13G     0.8557     0.7213      1.435          5        640: 100%|██████████| 1205/1205 [04:31<00:00,  4.44it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [02:18<00:00,  4.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.851      0.775      0.852      0.641\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/15      13.1G     0.8316     0.6653      1.414          5        640: 100%|██████████| 1205/1205 [04:27<00:00,  4.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [02:18<00:00,  4.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.865      0.785      0.864       0.65\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/15        13G     0.8043     0.6335      1.385          5        640: 100%|██████████| 1205/1205 [04:27<00:00,  4.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [02:18<00:00,  4.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.883        0.8      0.879      0.675\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/15        13G     0.7882     0.6116      1.368          5        640: 100%|██████████| 1205/1205 [04:28<00:00,  4.49it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [02:17<00:00,  4.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.879      0.819      0.893       0.69\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/15        13G     0.7659     0.5793       1.35          5        640: 100%|██████████| 1205/1205 [04:26<00:00,  4.52it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [02:18<00:00,  4.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.895      0.821      0.901      0.701\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      11/15      13.1G     0.7476      0.554       1.33        123        640: 100%|██████████| 1205/1205 [04:27<00:00,  4.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [02:18<00:00,  4.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.896      0.838       0.91      0.714\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      12/15        13G      0.724     0.5263      1.305          5        640: 100%|██████████| 1205/1205 [04:26<00:00,  4.52it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [02:18<00:00,  4.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.904      0.838      0.915      0.724\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      13/15        13G     0.7079     0.5013       1.29          6        640: 100%|██████████| 1205/1205 [04:28<00:00,  4.48it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [02:17<00:00,  4.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.916      0.848      0.923      0.737\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      14/15        13G     0.6926     0.4813      1.281          5        640: 100%|██████████| 1205/1205 [04:27<00:00,  4.50it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [02:18<00:00,  4.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.927      0.839      0.925      0.745\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      15/15      13.1G     0.6734     0.4638      1.262          5        640: 100%|██████████| 1205/1205 [04:26<00:00,  4.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [02:18<00:00,  4.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.926      0.856      0.936      0.757\n",
            "\n",
            "15 epochs completed in 1.888 hours.\n",
            "Optimizer stripped from runs/detect/train/weights/last.pt, 136.7MB\n",
            "Optimizer stripped from runs/detect/train/weights/best.pt, 136.7MB\n",
            "\n",
            "Validating runs/detect/train/weights/best.pt...\n",
            "Ultralytics YOLOv8.1.29 🚀 Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (NVIDIA A100-SXM4-40GB, 40514MiB)\n",
            "YOLOv8x summary (fused): 268 layers, 68128383 parameters, 0 gradients, 257.4 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [02:22<00:00,  4.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.926      0.856      0.936      0.757\n",
            "                 paper      19269       9173      0.959      0.928      0.978      0.864\n",
            "                 metal      19269       4423      0.959      0.953      0.985      0.839\n",
            "               plastic      19269       5659      0.926      0.823      0.912      0.694\n",
            "           other trash      19269       1630      0.901      0.762      0.896      0.657\n",
            "                 phone      19269       1217      0.885      0.816      0.905      0.731\n",
            "Speed: 0.1ms preprocess, 3.2ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/runs '/content/gdrive/My Drive/Dataset5-results/train3'"
      ],
      "metadata": {
        "id": "owtU_EwACwEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from ultralytics import YOLO\n",
        "import torch\n",
        "\n",
        "# Load a model\n",
        "model = YOLO(\"/content/gdrive/My Drive/Dataset5-results/train3/runs/detect/train/weights/last.pt\")   # Initialize a new model instance with the correct architecture configuration file\n",
        "\n",
        "\n",
        "# Define the number of epochs to train\n",
        "additional_epochs = 10\n",
        "\n",
        "# Use the model for training\n",
        "results = model.train(data=os.path.join(DATA_DIR, \"config2.yaml\"), epochs=additional_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T46fv2EoDGo4",
        "outputId": "4d247135-a14e-4d39-8841-236c1644f7b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.1.29 🚀 Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (NVIDIA A100-SXM4-40GB, 40514MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=/content/gdrive/My Drive/Dataset5-results/train3/runs/detect/train/weights/last.pt, data=/content/gdrive/My Drive/Dataset5/config2.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train2\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      2320  ultralytics.nn.modules.conv.Conv             [3, 80, 3, 2]                 \n",
            "  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n",
            "  2                  -1  3    436800  ultralytics.nn.modules.block.C2f             [160, 160, 3, True]           \n",
            "  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n",
            "  4                  -1  6   3281920  ultralytics.nn.modules.block.C2f             [320, 320, 6, True]           \n",
            "  5                  -1  1   1844480  ultralytics.nn.modules.conv.Conv             [320, 640, 3, 2]              \n",
            "  6                  -1  6  13117440  ultralytics.nn.modules.block.C2f             [640, 640, 6, True]           \n",
            "  7                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
            "  8                  -1  3   6969600  ultralytics.nn.modules.block.C2f             [640, 640, 3, True]           \n",
            "  9                  -1  1   1025920  ultralytics.nn.modules.block.SPPF            [640, 640, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  3   1948800  ultralytics.nn.modules.block.C2f             [960, 320, 3]                 \n",
            " 16                  -1  1    922240  ultralytics.nn.modules.conv.Conv             [320, 320, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  3   7174400  ultralytics.nn.modules.block.C2f             [960, 640, 3]                 \n",
            " 19                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
            " 22        [15, 18, 21]  1   8722783  ultralytics.nn.modules.head.Detect           [5, [320, 640, 640]]          \n",
            "YOLOv8x summary: 365 layers, 68157423 parameters, 68157407 gradients, 258.1 GFLOPs\n",
            "\n",
            "Transferred 595/595 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train2', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/gdrive/My Drive/Dataset5/labels.cache... 19277 images, 14 backgrounds, 8 corrupt: 100%|██████████| 19277/19277 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/AluCan39.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0469]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/AluCan48.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.002]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/AluCan55.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.013]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/AluCan87.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0339]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/beverage_cans-181_jpg.rf.94c07f03b7c6fce17d30eb60adc0396a.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/beverage_cans-181_jpg.rf.ecaffc6ad6effedba20a8c0a75bd0418.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/beverage_cans-379_jpg.rf.d589f287ed8221437b38862ec573af15.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/beverage_cans-782_jpg.rf.640cc1151be852d5f1afdcc6cc639115.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 3990, len(boxes) = 22102. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/gdrive/My Drive/Dataset5/labels.cache... 19277 images, 14 backgrounds, 8 corrupt: 100%|██████████| 19277/19277 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/AluCan39.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0469]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/AluCan48.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.002]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/AluCan55.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.013]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/AluCan87.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0339]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/beverage_cans-181_jpg.rf.94c07f03b7c6fce17d30eb60adc0396a.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/beverage_cans-181_jpg.rf.ecaffc6ad6effedba20a8c0a75bd0418.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/beverage_cans-379_jpg.rf.d589f287ed8221437b38862ec573af15.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/beverage_cans-782_jpg.rf.640cc1151be852d5f1afdcc6cc639115.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 3990, len(boxes) = 22102. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/detect/train2/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001111, momentum=0.9) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train2\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/10      13.3G     0.6829     0.4744      1.267          5        640: 100%|██████████| 1205/1205 [05:34<00:00,  3.60it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [02:17<00:00,  4.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.909       0.84      0.916      0.726\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/10      13.1G      0.733     0.5347      1.312          5        640: 100%|██████████| 1205/1205 [04:34<00:00,  4.38it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [02:18<00:00,  4.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.901      0.801      0.898      0.699\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/10      13.1G     0.7574     0.5727      1.341          5        640: 100%|██████████| 1205/1205 [04:28<00:00,  4.48it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [02:18<00:00,  4.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.885      0.812      0.892      0.691\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/10      13.1G     0.7571     0.5669      1.336          5        640: 100%|██████████| 1205/1205 [04:26<00:00,  4.52it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [02:17<00:00,  4.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.896      0.814        0.9      0.703\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/10      13.1G     0.7471     0.5591       1.33          5        640: 100%|██████████| 1205/1205 [04:26<00:00,  4.52it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [02:18<00:00,  4.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.896      0.829      0.906      0.706\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/10      13.1G     0.7324     0.5367      1.317          5        640: 100%|██████████| 1205/1205 [04:26<00:00,  4.52it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [02:17<00:00,  4.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.907      0.833      0.916      0.722\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/10      13.1G      0.713     0.5004      1.299          5        640: 100%|██████████| 1205/1205 [04:27<00:00,  4.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [02:17<00:00,  4.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.915      0.847      0.922      0.733\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/10      13.1G     0.6869     0.4776      1.271          5        640: 100%|██████████| 1205/1205 [04:27<00:00,  4.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [02:18<00:00,  4.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.926      0.853      0.932      0.752\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/10      13.1G     0.6638       0.45      1.251          5        640: 100%|██████████| 1205/1205 [04:27<00:00,  4.50it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [02:18<00:00,  4.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.916      0.873      0.941      0.767\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/10      13.1G     0.6439     0.4277      1.234          5        640: 100%|██████████| 1205/1205 [04:26<00:00,  4.52it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [02:17<00:00,  4.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.924      0.881      0.947      0.777\n",
            "\n",
            "10 epochs completed in 1.159 hours.\n",
            "Optimizer stripped from runs/detect/train2/weights/last.pt, 136.7MB\n",
            "Optimizer stripped from runs/detect/train2/weights/best.pt, 136.7MB\n",
            "\n",
            "Validating runs/detect/train2/weights/best.pt...\n",
            "Ultralytics YOLOv8.1.29 🚀 Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (NVIDIA A100-SXM4-40GB, 40514MiB)\n",
            "YOLOv8x summary (fused): 268 layers, 68128383 parameters, 0 gradients, 257.4 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [02:22<00:00,  4.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.924      0.881      0.947      0.777\n",
            "                 paper      19269       9173       0.96      0.948      0.984      0.877\n",
            "                 metal      19269       4423      0.969      0.957      0.989      0.856\n",
            "               plastic      19269       5659      0.925      0.848      0.921      0.712\n",
            "           other trash      19269       1630      0.893      0.802      0.919      0.691\n",
            "                 phone      19269       1217       0.87       0.85       0.92      0.752\n",
            "Speed: 0.1ms preprocess, 3.2ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train2\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/runs '/content/gdrive/My Drive/Dataset5-results/train3'"
      ],
      "metadata": {
        "id": "OvSQR2U7V3iG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from ultralytics import YOLO\n",
        "import torch\n",
        "\n",
        "# Load a model\n",
        "model = YOLO(\"/content/gdrive/My Drive/Dataset5/runs/detect/train2/weights/last.pt\")   # Initialize a new model instance with the correct architecture configuration file\n",
        "\n",
        "\n",
        "# Define the number of epochs to train\n",
        "additional_epochs = 1\n",
        "\n",
        "# Use the model for training\n",
        "results = model.train(data=os.path.join(DATA_DIR, \"config2.yaml\"), epochs=additional_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atn1AqUbP78h",
        "outputId": "89d2538b-924c-4ad1-8149-f3979bfba8bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.1.27 🚀 Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla V100-SXM2-16GB, 16151MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=/content/gdrive/My Drive/Dataset5/runs/detect/train2/weights/last.pt, data=/content/gdrive/My Drive/Dataset5/config2.yaml, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 755k/755k [00:00<00:00, 17.7MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      2320  ultralytics.nn.modules.conv.Conv             [3, 80, 3, 2]                 \n",
            "  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n",
            "  2                  -1  3    436800  ultralytics.nn.modules.block.C2f             [160, 160, 3, True]           \n",
            "  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n",
            "  4                  -1  6   3281920  ultralytics.nn.modules.block.C2f             [320, 320, 6, True]           \n",
            "  5                  -1  1   1844480  ultralytics.nn.modules.conv.Conv             [320, 640, 3, 2]              \n",
            "  6                  -1  6  13117440  ultralytics.nn.modules.block.C2f             [640, 640, 6, True]           \n",
            "  7                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
            "  8                  -1  3   6969600  ultralytics.nn.modules.block.C2f             [640, 640, 3, True]           \n",
            "  9                  -1  1   1025920  ultralytics.nn.modules.block.SPPF            [640, 640, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  3   1948800  ultralytics.nn.modules.block.C2f             [960, 320, 3]                 \n",
            " 16                  -1  1    922240  ultralytics.nn.modules.conv.Conv             [320, 320, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  3   7174400  ultralytics.nn.modules.block.C2f             [960, 640, 3]                 \n",
            " 19                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
            " 22        [15, 18, 21]  1   8722783  ultralytics.nn.modules.head.Detect           [5, [320, 640, 640]]          \n",
            "YOLOv8x summary: 365 layers, 68157423 parameters, 68157407 gradients, 258.1 GFLOPs\n",
            "\n",
            "Transferred 595/595 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8n.pt to 'yolov8n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6.23M/6.23M [00:00<00:00, 79.7MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/gdrive/My Drive/Dataset5/labels.cache... 19277 images, 14 backgrounds, 8 corrupt: 100%|██████████| 19277/19277 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/AluCan39.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0469]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/AluCan48.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.002]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/AluCan55.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.013]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/AluCan87.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0339]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/beverage_cans-181_jpg.rf.94c07f03b7c6fce17d30eb60adc0396a.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/beverage_cans-181_jpg.rf.ecaffc6ad6effedba20a8c0a75bd0418.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/beverage_cans-379_jpg.rf.d589f287ed8221437b38862ec573af15.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/beverage_cans-782_jpg.rf.640cc1151be852d5f1afdcc6cc639115.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 3990, len(boxes) = 22102. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/gdrive/My Drive/Dataset5/labels.cache... 19277 images, 14 backgrounds, 8 corrupt: 100%|██████████| 19277/19277 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/AluCan39.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0469]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/AluCan48.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.002]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/AluCan55.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.013]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/AluCan87.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0339]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/beverage_cans-181_jpg.rf.94c07f03b7c6fce17d30eb60adc0396a.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/beverage_cans-181_jpg.rf.ecaffc6ad6effedba20a8c0a75bd0418.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/beverage_cans-379_jpg.rf.d589f287ed8221437b38862ec573af15.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset5/images/beverage_cans-782_jpg.rf.640cc1151be852d5f1afdcc6cc639115.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 3990, len(boxes) = 22102. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001111, momentum=0.9) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
            "Starting training for 1 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        1/1      13.1G     0.9806      1.093      1.521         17        640: 100%|██████████| 1205/1205 [20:52<00:00,  1.04s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [09:06<00:00,  1.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.869      0.778      0.857      0.648\n",
            "\n",
            "1 epochs completed in 0.506 hours.\n",
            "Optimizer stripped from runs/detect/train/weights/last.pt, 136.7MB\n",
            "Optimizer stripped from runs/detect/train/weights/best.pt, 136.7MB\n",
            "\n",
            "Validating runs/detect/train/weights/best.pt...\n",
            "Ultralytics YOLOv8.1.27 🚀 Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla V100-SXM2-16GB, 16151MiB)\n",
            "YOLOv8x summary (fused): 268 layers, 68128383 parameters, 0 gradients, 257.4 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 603/603 [08:50<00:00,  1.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19269      22102      0.869      0.778      0.857      0.648\n",
            "                 paper      19269       9173      0.942      0.852      0.937      0.774\n",
            "                 metal      19269       4423      0.917      0.898       0.95      0.762\n",
            "               plastic      19269       5659      0.882      0.777      0.857      0.604\n",
            "           other trash      19269       1630      0.801      0.665      0.762      0.493\n",
            "                 phone      19269       1217      0.801        0.7       0.78      0.604\n",
            "Speed: 0.2ms preprocess, 6.3ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/runs '/content/gdrive/My Drive/Dataset5-results/train3'"
      ],
      "metadata": {
        "id": "hxK-0Z8kQ_0-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a model\n",
        "model = YOLO(\"yolov8x.yaml\") # build a new model from scratch\n",
        "\n",
        "# Use the model\n",
        "results = model.train(data=os.path.join(DATA_DIR, \"config2.yaml\"), epochs=20) # train the mode"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EfspSBhK2jlP",
        "outputId": "d0f1a35c-6d21-48bf-9e04-3205c930d83b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.1.25 🚀 Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (NVIDIA A100-SXM4-40GB, 40514MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8x.yaml, data=/content/gdrive/My Drive/Dataset4/config2.yaml, epochs=20, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 755k/755k [00:00<00:00, 27.9MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overriding model.yaml nc=80 with nc=5\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      2320  ultralytics.nn.modules.conv.Conv             [3, 80, 3, 2]                 \n",
            "  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n",
            "  2                  -1  3    436800  ultralytics.nn.modules.block.C2f             [160, 160, 3, True]           \n",
            "  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n",
            "  4                  -1  6   3281920  ultralytics.nn.modules.block.C2f             [320, 320, 6, True]           \n",
            "  5                  -1  1   1844480  ultralytics.nn.modules.conv.Conv             [320, 640, 3, 2]              \n",
            "  6                  -1  6  13117440  ultralytics.nn.modules.block.C2f             [640, 640, 6, True]           \n",
            "  7                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
            "  8                  -1  3   6969600  ultralytics.nn.modules.block.C2f             [640, 640, 3, True]           \n",
            "  9                  -1  1   1025920  ultralytics.nn.modules.block.SPPF            [640, 640, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  3   1948800  ultralytics.nn.modules.block.C2f             [960, 320, 3]                 \n",
            " 16                  -1  1    922240  ultralytics.nn.modules.conv.Conv             [320, 320, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  3   7174400  ultralytics.nn.modules.block.C2f             [960, 640, 3]                 \n",
            " 19                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
            " 22        [15, 18, 21]  1   8722783  ultralytics.nn.modules.head.Detect           [5, [320, 640, 640]]          \n",
            "YOLOv8x summary: 365 layers, 68157423 parameters, 68157407 gradients, 258.1 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8n.pt to 'yolov8n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6.23M/6.23M [00:00<00:00, 113MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/gdrive/My Drive/Dataset4/labels... 19427 images, 14 backgrounds, 30 corrupt: 100%|██████████| 19427/19427 [26:22<00:00, 12.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset4/images/000004_jpg.rf.c9a159f8264017cf3789597a0ec35c09.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.2436      11.513]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset4/images/000033_jpg.rf.81397dc4bc1a4ddf7d50ccfc136e47f3.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.2484      11.503]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset4/images/100192_jpg.rf.626f02bf792fc895def8b4f466a59a8c.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset4/images/300020_jpg.rf.011b0ac5fc15ba91ea72370ebb9deb23.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset4/images/300036_jpg.rf.354962c8183eadcbf08f1143b9fa3623.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset4/images/300063_jpg.rf.22763fea4cf264c6bea75f2ed0f5ae23.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset4/images/300070_jpg.rf.c47e7acb6abb61f3bd24449593f810d6.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset4/images/400015_jpg.rf.76bc655fb8d27c1a9d1618b56b8870c0.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset4/images/400059_jpg.rf.78d834f4e1cb9c9c346210d7a775e324.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset4/images/400088_jpg.rf.eda018ddf27f1c22d7f45761b0a75798.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset4/images/400107_jpg.rf.515f55a1de9cc99c0c409ba334731d2d.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset4/images/500051_jpg.rf.e010263d0d9533b14e004e7d0fa2d518.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      6.191      11.618]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset4/images/500582_jpg.rf.2c885f30ad0bb21ea44663154df30e84.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset4/images/800140_jpg.rf.e7fbf0cc198ccf822a64e158d1025786.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset4/images/800296_jpg.rf.b261b050b62caf5b8905ab5207ec58aa.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.19       11.62]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset4/images/800296_jpg.rf.f11935209d6c47d3ea26752683ae8eb3.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [          6          12]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset4/images/800471_jpg.rf.f29cf04ec2913275af298e6b91e747a1.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.2496      11.501]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset4/images/900077_jpg.rf.cc14589cb4b2cd9a8047c8c9409e6f73.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.2343      11.531]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset4/images/AluCan39.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0469]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset4/images/AluCan48.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.002]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset4/images/AluCan55.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.013]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset4/images/AluCan87.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0339]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset4/images/beverage_cans-181_jpg.rf.94c07f03b7c6fce17d30eb60adc0396a.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset4/images/beverage_cans-181_jpg.rf.ecaffc6ad6effedba20a8c0a75bd0418.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset4/images/beverage_cans-379_jpg.rf.d589f287ed8221437b38862ec573af15.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset4/images/beverage_cans-782_jpg.rf.640cc1151be852d5f1afdcc6cc639115.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset4/images/image_png.rf.1a276c55e373ab8b9f54b8edc3ef2b1d.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.018]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset4/images/plastic_bottle-249_jpg.rf.36fd97c36d8977da282b6ae11442c8d4.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset4/images/sirma-su-pet-050-lt-80b6_jpg.rf.7daabbcea204232761d8e2c76b7b1c35.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [        6.2        11.6]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset4/images/water-bottles_jpg.rf.7f2cf644e7b419c297daade95476a192.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0048      1.0135]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/gdrive/My Drive/Dataset4/labels.cache\n",
            "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 3170, len(boxes) = 19383. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/gdrive/My Drive/Dataset4/labels.cache... 19427 images, 14 backgrounds, 30 corrupt: 100%|██████████| 19427/19427 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset4/images/000004_jpg.rf.c9a159f8264017cf3789597a0ec35c09.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.2436      11.513]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset4/images/000033_jpg.rf.81397dc4bc1a4ddf7d50ccfc136e47f3.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.2484      11.503]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset4/images/100192_jpg.rf.626f02bf792fc895def8b4f466a59a8c.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset4/images/300020_jpg.rf.011b0ac5fc15ba91ea72370ebb9deb23.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset4/images/300036_jpg.rf.354962c8183eadcbf08f1143b9fa3623.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset4/images/300063_jpg.rf.22763fea4cf264c6bea75f2ed0f5ae23.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset4/images/300070_jpg.rf.c47e7acb6abb61f3bd24449593f810d6.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset4/images/400015_jpg.rf.76bc655fb8d27c1a9d1618b56b8870c0.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset4/images/400059_jpg.rf.78d834f4e1cb9c9c346210d7a775e324.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset4/images/400088_jpg.rf.eda018ddf27f1c22d7f45761b0a75798.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset4/images/400107_jpg.rf.515f55a1de9cc99c0c409ba334731d2d.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset4/images/500051_jpg.rf.e010263d0d9533b14e004e7d0fa2d518.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      6.191      11.618]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset4/images/500582_jpg.rf.2c885f30ad0bb21ea44663154df30e84.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset4/images/800140_jpg.rf.e7fbf0cc198ccf822a64e158d1025786.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset4/images/800296_jpg.rf.b261b050b62caf5b8905ab5207ec58aa.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.19       11.62]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset4/images/800296_jpg.rf.f11935209d6c47d3ea26752683ae8eb3.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [          6          12]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset4/images/800471_jpg.rf.f29cf04ec2913275af298e6b91e747a1.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.2496      11.501]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset4/images/900077_jpg.rf.cc14589cb4b2cd9a8047c8c9409e6f73.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.2343      11.531]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset4/images/AluCan39.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0469]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset4/images/AluCan48.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.002]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset4/images/AluCan55.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.013]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset4/images/AluCan87.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0339]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset4/images/beverage_cans-181_jpg.rf.94c07f03b7c6fce17d30eb60adc0396a.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset4/images/beverage_cans-181_jpg.rf.ecaffc6ad6effedba20a8c0a75bd0418.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset4/images/beverage_cans-379_jpg.rf.d589f287ed8221437b38862ec573af15.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset4/images/beverage_cans-782_jpg.rf.640cc1151be852d5f1afdcc6cc639115.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset4/images/image_png.rf.1a276c55e373ab8b9f54b8edc3ef2b1d.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.018]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset4/images/plastic_bottle-249_jpg.rf.36fd97c36d8977da282b6ae11442c8d4.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset4/images/sirma-su-pet-050-lt-80b6_jpg.rf.7daabbcea204232761d8e2c76b7b1c35.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [        6.2        11.6]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset4/images/water-bottles_jpg.rf.7f2cf644e7b419c297daade95476a192.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0048      1.0135]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 3170, len(boxes) = 19383. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "Plotting labels to runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001111, momentum=0.9) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/20      13.3G      2.206      3.274      2.934          9        640: 100%|██████████| 1213/1213 [06:45<00:00,  2.99it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 607/607 [02:57<00:00,  3.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19397      19383      0.543      0.163      0.127      0.069\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/20      13.1G      1.478      2.281      2.086          9        640: 100%|██████████| 1213/1213 [04:41<00:00,  4.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 607/607 [02:48<00:00,  3.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19397      19383      0.678       0.23      0.252      0.161\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/20      13.1G      1.332      1.992       1.92         12        640: 100%|██████████| 1213/1213 [04:34<00:00,  4.42it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 607/607 [02:49<00:00,  3.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19397      19383      0.497      0.401      0.352      0.232\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/20        13G      1.243      1.792      1.822         12        640: 100%|██████████| 1213/1213 [04:33<00:00,  4.44it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 607/607 [02:49<00:00,  3.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19397      19383      0.648      0.418      0.428      0.289\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/20      13.1G      1.166      1.613      1.747          9        640: 100%|██████████| 1213/1213 [04:32<00:00,  4.46it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 607/607 [02:48<00:00,  3.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19397      19383      0.471      0.515      0.493      0.333\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/20        13G      1.131      1.501       1.71         11        640: 100%|██████████| 1213/1213 [04:32<00:00,  4.45it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 607/607 [02:49<00:00,  3.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19397      19383      0.607      0.557       0.56      0.381\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/20        13G      1.089      1.402      1.665         11        640: 100%|██████████| 1213/1213 [04:35<00:00,  4.41it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 607/607 [02:49<00:00,  3.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19397      19383      0.628      0.605      0.616       0.43\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/20        13G       1.05      1.315      1.622         14        640: 100%|██████████| 1213/1213 [04:32<00:00,  4.45it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 607/607 [02:48<00:00,  3.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19397      19383      0.659       0.62      0.643      0.453\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/20      13.1G      1.028      1.263      1.606         14        640: 100%|██████████| 1213/1213 [04:33<00:00,  4.43it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 607/607 [02:49<00:00,  3.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19397      19383      0.682      0.656      0.673       0.47\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/20        13G      1.009       1.21      1.589          8        640: 100%|██████████| 1213/1213 [04:35<00:00,  4.41it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 607/607 [02:48<00:00,  3.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19397      19383      0.721      0.671      0.697      0.497\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      11/20        13G     0.9911      1.021      1.621          5        640: 100%|██████████| 1213/1213 [04:36<00:00,  4.39it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 607/607 [02:48<00:00,  3.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19397      19383      0.741      0.689      0.722      0.517\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      12/20        13G     0.9482     0.9544      1.573          5        640: 100%|██████████| 1213/1213 [04:31<00:00,  4.46it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 607/607 [02:49<00:00,  3.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19397      19383      0.786      0.697      0.741      0.542\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      13/20      13.1G     0.9265     0.9047      1.547          5        640: 100%|██████████| 1213/1213 [04:33<00:00,  4.43it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 607/607 [02:49<00:00,  3.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19397      19383      0.789      0.707      0.756      0.564\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      14/20        13G      0.899     0.8592      1.526          5        640: 100%|██████████| 1213/1213 [04:32<00:00,  4.45it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 607/607 [02:48<00:00,  3.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19397      19383      0.818      0.727       0.78       0.58\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      15/20        13G     0.8761     0.8231      1.505          5        640: 100%|██████████| 1213/1213 [04:33<00:00,  4.44it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 607/607 [02:49<00:00,  3.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19397      19383      0.817      0.731      0.789      0.596\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      16/20        13G     0.8515     0.7887      1.469          5        640: 100%|██████████| 1213/1213 [04:32<00:00,  4.46it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 607/607 [02:48<00:00,  3.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19397      19383      0.825      0.742      0.802      0.611\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      17/20        13G     0.8381     0.7494      1.459          5        640: 100%|██████████| 1213/1213 [04:33<00:00,  4.43it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 607/607 [02:47<00:00,  3.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19397      19383      0.826      0.754       0.81      0.621\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      18/20        13G     0.8132     0.7242      1.431          5        640: 100%|██████████| 1213/1213 [04:34<00:00,  4.43it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 607/607 [02:54<00:00,  3.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19397      19383      0.841      0.752      0.817       0.63\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      19/20        13G      0.797     0.6955      1.413          5        640: 100%|██████████| 1213/1213 [04:39<00:00,  4.35it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 607/607 [02:55<00:00,  3.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19397      19383      0.845      0.762      0.826      0.642\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      20/20        13G     0.7758     0.6678      1.391          5        640: 100%|██████████| 1213/1213 [04:37<00:00,  4.37it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 607/607 [02:54<00:00,  3.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19397      19383      0.855      0.764       0.83       0.65\n",
            "\n",
            "20 epochs completed in 2.543 hours.\n",
            "Optimizer stripped from runs/detect/train/weights/last.pt, 136.7MB\n",
            "Optimizer stripped from runs/detect/train/weights/best.pt, 136.7MB\n",
            "\n",
            "Validating runs/detect/train/weights/best.pt...\n",
            "Ultralytics YOLOv8.1.25 🚀 Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (NVIDIA A100-SXM4-40GB, 40514MiB)\n",
            "YOLOv8x summary (fused): 268 layers, 68128383 parameters, 0 gradients, 257.4 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 607/607 [02:58<00:00,  3.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      19397      19383      0.855      0.764       0.83       0.65\n",
            "                 paper      19397       9173      0.931      0.899      0.956      0.825\n",
            "                 metal      19397       3956      0.954      0.941      0.981      0.815\n",
            "               plastic      19397       3969      0.715      0.492       0.55      0.381\n",
            "           other trash      19397       1068      0.802      0.717      0.811      0.555\n",
            "                 phone      19397       1217      0.876      0.769      0.854      0.673\n",
            "Speed: 0.1ms preprocess, 3.1ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3_ePE0nZtks0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/runs '/content/gdrive/My Drive/Dataset4'"
      ],
      "metadata": {
        "id": "L-sYW0TSi5qJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!scp -r /content/runs '/content/gdrive/My Drive/Dataset4'"
      ],
      "metadata": {
        "id": "BF11A6fA3mM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from ultralytics import YOLO\n",
        "import torch\n",
        "\n",
        "# Load a model\n",
        "model = YOLO(\"/content/gdrive/My Drive/Dataset4/runs/detect/train/weights/last.pt\")   # Initialize a new model instance with the correct architecture configuration file\n",
        "\n",
        "\n",
        "# Define the number of epochs to train\n",
        "additional_epochs = 10\n",
        "\n",
        "# Use the model for training\n",
        "results = model.train(data=os.path.join(DATA_DIR, \"config2.yaml\"), epochs=additional_epochs)"
      ],
      "metadata": {
        "id": "8s0CIf7BmNVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a model\n",
        "model = YOLO(\"yolov8m.yaml\") # build a new model from scratch\n",
        "\n",
        "# Use the model\n",
        "results = model.train(data=os.path.join(DATA_DIR, \"config2.yaml\"), epochs=1) # train the model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83TJ4p0ShuVN",
        "outputId": "5140f5dc-d03b-45cb-c53e-b71886715071"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.1.16 🚀 Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (NVIDIA A100-SXM4-40GB, 40514MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8m.yaml, data=/content/gdrive/My Drive/Dataset2/config2.yaml, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 755k/755k [00:00<00:00, 114MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overriding model.yaml nc=80 with nc=3\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
            "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
            "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
            "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
            "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
            "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
            "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
            "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
            "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
            "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
            " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
            " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
            " 22        [15, 18, 21]  1   3777433  ultralytics.nn.modules.head.Detect           [3, [192, 384, 576]]          \n",
            "YOLOv8m summary: 295 layers, 25858057 parameters, 25858041 gradients, 79.1 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8n.pt to 'yolov8n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6.23M/6.23M [00:00<00:00, 335MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/gdrive/My Drive/Dataset2/labels.cache... 9961 images, 10 backgrounds, 30 corrupt: 100%|██████████| 9961/9961 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/000004_jpg.rf.c9a159f8264017cf3789597a0ec35c09.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.2436      11.513]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/000033_jpg.rf.81397dc4bc1a4ddf7d50ccfc136e47f3.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.2484      11.503]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/100192_jpg.rf.626f02bf792fc895def8b4f466a59a8c.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/300020_jpg.rf.011b0ac5fc15ba91ea72370ebb9deb23.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/300036_jpg.rf.354962c8183eadcbf08f1143b9fa3623.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/300063_jpg.rf.22763fea4cf264c6bea75f2ed0f5ae23.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/300070_jpg.rf.c47e7acb6abb61f3bd24449593f810d6.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/400015_jpg.rf.76bc655fb8d27c1a9d1618b56b8870c0.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/400059_jpg.rf.78d834f4e1cb9c9c346210d7a775e324.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/400088_jpg.rf.eda018ddf27f1c22d7f45761b0a75798.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/400107_jpg.rf.515f55a1de9cc99c0c409ba334731d2d.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/500051_jpg.rf.e010263d0d9533b14e004e7d0fa2d518.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      6.191      11.618]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/500582_jpg.rf.2c885f30ad0bb21ea44663154df30e84.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/800140_jpg.rf.e7fbf0cc198ccf822a64e158d1025786.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/800296_jpg.rf.b261b050b62caf5b8905ab5207ec58aa.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.19       11.62]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/800296_jpg.rf.f11935209d6c47d3ea26752683ae8eb3.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [          6          12]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/800471_jpg.rf.f29cf04ec2913275af298e6b91e747a1.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.2496      11.501]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/900077_jpg.rf.cc14589cb4b2cd9a8047c8c9409e6f73.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.2343      11.531]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/AluCan39.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0469]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/AluCan48.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.002]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/AluCan55.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.013]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/AluCan87.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0339]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/beverage_cans-181_jpg.rf.94c07f03b7c6fce17d30eb60adc0396a.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/beverage_cans-181_jpg.rf.ecaffc6ad6effedba20a8c0a75bd0418.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/beverage_cans-379_jpg.rf.d589f287ed8221437b38862ec573af15.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/beverage_cans-782_jpg.rf.640cc1151be852d5f1afdcc6cc639115.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/image_png.rf.1a276c55e373ab8b9f54b8edc3ef2b1d.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.018]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/plastic_bottle-249_jpg.rf.36fd97c36d8977da282b6ae11442c8d4.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/sirma-su-pet-050-lt-80b6_jpg.rf.7daabbcea204232761d8e2c76b7b1c35.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [        6.2        11.6]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/water-bottles_jpg.rf.7f2cf644e7b419c297daade95476a192.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0048      1.0135]\n",
            "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 1266, len(boxes) = 10479. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/gdrive/My Drive/Dataset2/labels.cache... 9961 images, 10 backgrounds, 30 corrupt: 100%|██████████| 9961/9961 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/000004_jpg.rf.c9a159f8264017cf3789597a0ec35c09.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.2436      11.513]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/000033_jpg.rf.81397dc4bc1a4ddf7d50ccfc136e47f3.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.2484      11.503]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/100192_jpg.rf.626f02bf792fc895def8b4f466a59a8c.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/300020_jpg.rf.011b0ac5fc15ba91ea72370ebb9deb23.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/300036_jpg.rf.354962c8183eadcbf08f1143b9fa3623.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/300063_jpg.rf.22763fea4cf264c6bea75f2ed0f5ae23.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/300070_jpg.rf.c47e7acb6abb61f3bd24449593f810d6.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/400015_jpg.rf.76bc655fb8d27c1a9d1618b56b8870c0.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/400059_jpg.rf.78d834f4e1cb9c9c346210d7a775e324.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/400088_jpg.rf.eda018ddf27f1c22d7f45761b0a75798.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/400107_jpg.rf.515f55a1de9cc99c0c409ba334731d2d.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/500051_jpg.rf.e010263d0d9533b14e004e7d0fa2d518.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      6.191      11.618]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/500582_jpg.rf.2c885f30ad0bb21ea44663154df30e84.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/800140_jpg.rf.e7fbf0cc198ccf822a64e158d1025786.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/800296_jpg.rf.b261b050b62caf5b8905ab5207ec58aa.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.19       11.62]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/800296_jpg.rf.f11935209d6c47d3ea26752683ae8eb3.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [          6          12]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/800471_jpg.rf.f29cf04ec2913275af298e6b91e747a1.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.2496      11.501]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/900077_jpg.rf.cc14589cb4b2cd9a8047c8c9409e6f73.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.2343      11.531]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/AluCan39.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0469]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/AluCan48.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.002]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/AluCan55.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.013]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/AluCan87.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0339]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/beverage_cans-181_jpg.rf.94c07f03b7c6fce17d30eb60adc0396a.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/beverage_cans-181_jpg.rf.ecaffc6ad6effedba20a8c0a75bd0418.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/beverage_cans-379_jpg.rf.d589f287ed8221437b38862ec573af15.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/beverage_cans-782_jpg.rf.640cc1151be852d5f1afdcc6cc639115.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/image_png.rf.1a276c55e373ab8b9f54b8edc3ef2b1d.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.018]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/plastic_bottle-249_jpg.rf.36fd97c36d8977da282b6ae11442c8d4.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/sirma-su-pet-050-lt-80b6_jpg.rf.7daabbcea204232761d8e2c76b7b1c35.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [        6.2        11.6]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/water-bottles_jpg.rf.7f2cf644e7b419c297daade95476a192.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0048      1.0135]\n",
            "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 1266, len(boxes) = 10479. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
            "Starting training for 1 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        1/1      7.03G      2.794      3.903      3.542         34        640: 100%|██████████| 621/621 [07:20<00:00,  1.41it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 311/311 [01:33<00:00,  3.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       9931      10479      0.387     0.0495     0.0216    0.00694\n",
            "\n",
            "1 epochs completed in 0.151 hours.\n",
            "Optimizer stripped from runs/detect/train/weights/last.pt, 52.0MB\n",
            "Optimizer stripped from runs/detect/train/weights/best.pt, 52.0MB\n",
            "\n",
            "Validating runs/detect/train/weights/best.pt...\n",
            "Ultralytics YOLOv8.1.16 🚀 Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (NVIDIA A100-SXM4-40GB, 40514MiB)\n",
            "YOLOv8m summary (fused): 218 layers, 25841497 parameters, 0 gradients, 78.7 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 311/311 [01:24<00:00,  3.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       9931      10479      0.387     0.0496     0.0216    0.00694\n",
            "                 paper       9931       2554     0.0665      0.029     0.0236    0.00758\n",
            "                 metal       9931       3956     0.0931       0.12     0.0323     0.0106\n",
            "               plastic       9931       3969          1          0    0.00888    0.00265\n",
            "Speed: 0.1ms preprocess, 1.4ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "iYCrFGFfngii",
        "outputId": "1f2315de-d9d1-416b-b5ac-4055d83800c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!locale"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "CsVIEqT0oGcI",
        "outputId": "9fb0153b-4378-4ff9-ebdd-1c64e7515229"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotImplementedError",
          "evalue": "A UTF-8 locale is required. Got ANSI_X3.4-1968",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-3156e0244c83>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'locale'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'also_return_output'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_system_commands\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_system_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_warn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_system_compat\u001b[0;34m(shell, cmd, also_return_output)\u001b[0m\n\u001b[1;32m    452\u001b[0m   \u001b[0;31m# is expected to call this function, thus adding one level of nesting to the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m   \u001b[0;31m# stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m   result = _run_command(\n\u001b[0m\u001b[1;32m    455\u001b[0m       \u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear_streamed_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_run_command\u001b[0;34m(cmd, clear_streamed_output)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0mlocale_encoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpreferredencoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlocale_encoding\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0m_ENCODING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m       raise NotImplementedError(\n\u001b[0m\u001b[1;32m    169\u001b[0m           \u001b[0;34m'A UTF-8 locale is required. Got {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocale_encoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m       )\n",
            "\u001b[0;31mNotImplementedError\u001b[0m: A UTF-8 locale is required. Got ANSI_X3.4-1968"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/runs '/content/gdrive/My Drive/Dataset2'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "RXJhIDU6lIFo",
        "outputId": "fdef4621-5fd3-4fb6-f28a-cf9bf1b2485f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotImplementedError",
          "evalue": "A UTF-8 locale is required. Got ANSI_X3.4-1968",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-ce71ff417c46>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cp -r /content/runs '/content/gdrive/My Drive/Dataset2'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'also_return_output'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_system_commands\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_system_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_warn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_system_compat\u001b[0;34m(shell, cmd, also_return_output)\u001b[0m\n\u001b[1;32m    452\u001b[0m   \u001b[0;31m# is expected to call this function, thus adding one level of nesting to the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m   \u001b[0;31m# stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m   result = _run_command(\n\u001b[0m\u001b[1;32m    455\u001b[0m       \u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear_streamed_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_run_command\u001b[0;34m(cmd, clear_streamed_output)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0mlocale_encoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpreferredencoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlocale_encoding\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0m_ENCODING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m       raise NotImplementedError(\n\u001b[0m\u001b[1;32m    169\u001b[0m           \u001b[0;34m'A UTF-8 locale is required. Got {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocale_encoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m       )\n",
            "\u001b[0;31mNotImplementedError\u001b[0m: A UTF-8 locale is required. Got ANSI_X3.4-1968"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCxZX-WyIMCT",
        "outputId": "a40cb988-3086-4b59-ddcc-bb7c32bfedc4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics YOLOv8.1.12 🚀 Python-3.10.12 torch-2.1.0+cu121 CPU (Intel Xeon 2.20GHz)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.yaml, data=/content/gdrive/My Drive/Dataset0/train/config2.yaml, epochs=12, time=None, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train3, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train3\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 755k/755k [00:00<00:00, 15.6MB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overriding model.yaml nc=80 with nc=3\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751897  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
            "YOLOv8n summary: 225 layers, 3011433 parameters, 3011417 gradients, 8.2 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train3', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/gdrive/My Drive/Dataset0/train/labels... 6362 images, 35 backgrounds, 27 corrupt: 100%|██████████| 6393/6393 [32:24<00:00,  3.29it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset0/train/images/AluCan39.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0469]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset0/train/images/AluCan48.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.002]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset0/train/images/AluCan55.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.013]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset0/train/images/AluCan87.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0339]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset0/train/images/pwb1036_jpg.rf.caaba8995263758605da7854bc93082e.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset0/train/images/pwb1177_jpg.rf.704b832861ce2331d9cca003133d55ea.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset0/train/images/pwb1237_jpg.rf.d57fdd0d815f57124b5da2c5b6113c97.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      6.168      11.664]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset0/train/images/pwb1308_jpg.rf.b18507c6a11dc5a23e2a5aabf57be497.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset0/train/images/pwb1363_jpg.rf.0464694ea878b1d1356874de6696e2fa.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      6.243      11.514]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset0/train/images/pwb1375_jpg.rf.d90bee91ec506159a63d35f9963942a4.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset0/train/images/pwb1414_jpg.rf.051483a23933bb704b39ebf14f89619e.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset0/train/images/pwb151_jpg.rf.02111191b6515757c568faab6f23292c.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset0/train/images/pwb1607_jpg.rf.214cd855b10cdea7a4dbfae01848e644.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset0/train/images/pwb2132_jpg.rf.dd46553b93a549c50a1bdddf12888c35.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset0/train/images/pwb2133_jpg.rf.5a37dc2018c8b365f589da69898c126f.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.0352       11.93]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset0/train/images/pwb2177_jpg.rf.d4d2e1323047e38a1489bfb0de5494de.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.1406      11.719]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset0/train/images/pwb2242_jpg.rf.b8272b417129b6981281583f37aecdb0.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.0371      11.926]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset0/train/images/pwb2261_jpg.rf.832c87841c4abf42eef2534426a18ec7.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.2363      11.527]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset0/train/images/pwb2269_jpg.rf.4d0cde4fe7330d86d29acd822f1c6579.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.0113      11.977]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset0/train/images/pwb391_jpg.rf.2d8350bb2fe67ccad1b2dc16674e280f.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.2402       11.52]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset0/train/images/pwb44_jpg.rf.c4bd52682ecf57de05647c351f38856b.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset0/train/images/pwb548_jpg.rf.ac99495ff4bdcef2acba8ea7e6aa7b89.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.0789      11.842]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset0/train/images/pwb548_jpg.rf.dc017647d074ef0d256ba14ceadebf3e.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.0789      11.842]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset0/train/images/pwb707_jpg.rf.4317aab61bf86418c669a6371aad781e.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset0/train/images/pwb882_jpg.rf.db068089ceb4762b90a514c26636f6e6.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset0/train/images/pwb933_jpg.rf.bfbc408be4b0139dc28d7dc3dee43ef5.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.1844      11.631]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset0/train/images/pwb939_jpg.rf.38c960c1cd915b112d4feb04696e09a0.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/gdrive/My Drive/Dataset0/train/labels.cache\n",
            "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 901, len(boxes) = 6904. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/gdrive/My Drive/Dataset0/train/labels.cache... 6362 images, 35 backgrounds, 27 corrupt: 100%|██████████| 6393/6393 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset0/train/images/AluCan39.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0469]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset0/train/images/AluCan48.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.002]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset0/train/images/AluCan55.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.013]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset0/train/images/AluCan87.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0339]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset0/train/images/pwb1036_jpg.rf.caaba8995263758605da7854bc93082e.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset0/train/images/pwb1177_jpg.rf.704b832861ce2331d9cca003133d55ea.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset0/train/images/pwb1237_jpg.rf.d57fdd0d815f57124b5da2c5b6113c97.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      6.168      11.664]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset0/train/images/pwb1308_jpg.rf.b18507c6a11dc5a23e2a5aabf57be497.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset0/train/images/pwb1363_jpg.rf.0464694ea878b1d1356874de6696e2fa.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      6.243      11.514]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset0/train/images/pwb1375_jpg.rf.d90bee91ec506159a63d35f9963942a4.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset0/train/images/pwb1414_jpg.rf.051483a23933bb704b39ebf14f89619e.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset0/train/images/pwb151_jpg.rf.02111191b6515757c568faab6f23292c.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset0/train/images/pwb1607_jpg.rf.214cd855b10cdea7a4dbfae01848e644.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset0/train/images/pwb2132_jpg.rf.dd46553b93a549c50a1bdddf12888c35.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset0/train/images/pwb2133_jpg.rf.5a37dc2018c8b365f589da69898c126f.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.0352       11.93]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset0/train/images/pwb2177_jpg.rf.d4d2e1323047e38a1489bfb0de5494de.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.1406      11.719]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset0/train/images/pwb2242_jpg.rf.b8272b417129b6981281583f37aecdb0.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.0371      11.926]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset0/train/images/pwb2261_jpg.rf.832c87841c4abf42eef2534426a18ec7.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.2363      11.527]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset0/train/images/pwb2269_jpg.rf.4d0cde4fe7330d86d29acd822f1c6579.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.0113      11.977]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset0/train/images/pwb391_jpg.rf.2d8350bb2fe67ccad1b2dc16674e280f.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.2402       11.52]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset0/train/images/pwb44_jpg.rf.c4bd52682ecf57de05647c351f38856b.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset0/train/images/pwb548_jpg.rf.ac99495ff4bdcef2acba8ea7e6aa7b89.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.0789      11.842]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset0/train/images/pwb548_jpg.rf.dc017647d074ef0d256ba14ceadebf3e.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.0789      11.842]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset0/train/images/pwb707_jpg.rf.4317aab61bf86418c669a6371aad781e.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset0/train/images/pwb882_jpg.rf.db068089ceb4762b90a514c26636f6e6.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset0/train/images/pwb933_jpg.rf.bfbc408be4b0139dc28d7dc3dee43ef5.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.1844      11.631]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset0/train/images/pwb939_jpg.rf.38c960c1cd915b112d4feb04696e09a0.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 901, len(boxes) = 6904. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "Plotting labels to runs/detect/train3/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train3\u001b[0m\n",
            "Starting training for 12 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       1/12         0G      2.972      3.983      3.847         46        640: 100%|██████████| 398/398 [1:35:24<00:00, 14.38s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 199/199 [40:25<00:00, 12.19s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all       6366       6904      0.162     0.0665      0.026    0.00698\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       2/12         0G      2.207      3.298      2.819         31        640: 100%|██████████| 398/398 [1:30:53<00:00, 13.70s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 199/199 [38:44<00:00, 11.68s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all       6366       6904      0.309      0.224      0.155     0.0642\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       3/12         0G      1.723      2.512      2.431         14        640: 100%|██████████| 398/398 [1:44:10<00:00, 15.71s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 199/199 [38:42<00:00, 11.67s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all       6366       6904      0.491       0.44      0.416       0.24\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       4/12         0G      1.495       2.06      2.154         14        640: 100%|██████████| 398/398 [1:31:08<00:00, 13.74s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 199/199 [35:12<00:00, 10.62s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all       6366       6904      0.548      0.492      0.504       0.32\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       5/12         0G      1.371      1.832      2.016         16        640:  93%|█████████▎| 369/398 [1:31:13<07:04, 14.64s/it]"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a model\n",
        "model = YOLO(\"yolov8n.yaml\") # build a new model from scratch\n",
        "\n",
        "# Use the model\n",
        "results = model.train(data=os.path.join(DATA_DIR, \"config2.yaml\"), epochs=12) # train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cW3hM95Fb73",
        "outputId": "9033653a-a6b1-4b83-d8d8-1a9663a0196b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics YOLOv8.1.14 🚀 Python-3.10.12 torch-2.1.0+cu121 CPU (Intel Xeon 2.20GHz)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.yaml, data=/content/gdrive/My Drive/Dataset2/config2.yaml, epochs=1, time=None, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 755k/755k [00:00<00:00, 15.3MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overriding model.yaml nc=80 with nc=3\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751897  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
            "YOLOv8n summary: 225 layers, 3011433 parameters, 3011417 gradients, 8.2 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/gdrive/My Drive/Dataset2/labels... 9961 images, 10 backgrounds, 30 corrupt: 100%|██████████| 9961/9961 [53:55<00:00,  3.08it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/000004_jpg.rf.c9a159f8264017cf3789597a0ec35c09.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.2436      11.513]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/000033_jpg.rf.81397dc4bc1a4ddf7d50ccfc136e47f3.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.2484      11.503]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/100192_jpg.rf.626f02bf792fc895def8b4f466a59a8c.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/300020_jpg.rf.011b0ac5fc15ba91ea72370ebb9deb23.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/300036_jpg.rf.354962c8183eadcbf08f1143b9fa3623.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/300063_jpg.rf.22763fea4cf264c6bea75f2ed0f5ae23.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/300070_jpg.rf.c47e7acb6abb61f3bd24449593f810d6.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/400015_jpg.rf.76bc655fb8d27c1a9d1618b56b8870c0.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/400059_jpg.rf.78d834f4e1cb9c9c346210d7a775e324.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/400088_jpg.rf.eda018ddf27f1c22d7f45761b0a75798.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/400107_jpg.rf.515f55a1de9cc99c0c409ba334731d2d.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/500051_jpg.rf.e010263d0d9533b14e004e7d0fa2d518.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      6.191      11.618]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/500582_jpg.rf.2c885f30ad0bb21ea44663154df30e84.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/800140_jpg.rf.e7fbf0cc198ccf822a64e158d1025786.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/800296_jpg.rf.b261b050b62caf5b8905ab5207ec58aa.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.19       11.62]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/800296_jpg.rf.f11935209d6c47d3ea26752683ae8eb3.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [          6          12]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/800471_jpg.rf.f29cf04ec2913275af298e6b91e747a1.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.2496      11.501]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/900077_jpg.rf.cc14589cb4b2cd9a8047c8c9409e6f73.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.2343      11.531]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/AluCan39.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0469]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/AluCan48.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.002]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/AluCan55.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.013]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/AluCan87.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0339]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/beverage_cans-181_jpg.rf.94c07f03b7c6fce17d30eb60adc0396a.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/beverage_cans-181_jpg.rf.ecaffc6ad6effedba20a8c0a75bd0418.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/beverage_cans-379_jpg.rf.d589f287ed8221437b38862ec573af15.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/beverage_cans-782_jpg.rf.640cc1151be852d5f1afdcc6cc639115.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/image_png.rf.1a276c55e373ab8b9f54b8edc3ef2b1d.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.018]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/plastic_bottle-249_jpg.rf.36fd97c36d8977da282b6ae11442c8d4.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/sirma-su-pet-050-lt-80b6_jpg.rf.7daabbcea204232761d8e2c76b7b1c35.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [        6.2        11.6]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/water-bottles_jpg.rf.7f2cf644e7b419c297daade95476a192.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0048      1.0135]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/gdrive/My Drive/Dataset2/labels.cache\n",
            "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 1266, len(boxes) = 10479. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/gdrive/My Drive/Dataset2/labels.cache... 9961 images, 10 backgrounds, 30 corrupt: 100%|██████████| 9961/9961 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/000004_jpg.rf.c9a159f8264017cf3789597a0ec35c09.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.2436      11.513]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/000033_jpg.rf.81397dc4bc1a4ddf7d50ccfc136e47f3.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.2484      11.503]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/100192_jpg.rf.626f02bf792fc895def8b4f466a59a8c.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/300020_jpg.rf.011b0ac5fc15ba91ea72370ebb9deb23.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/300036_jpg.rf.354962c8183eadcbf08f1143b9fa3623.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/300063_jpg.rf.22763fea4cf264c6bea75f2ed0f5ae23.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/300070_jpg.rf.c47e7acb6abb61f3bd24449593f810d6.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/400015_jpg.rf.76bc655fb8d27c1a9d1618b56b8870c0.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/400059_jpg.rf.78d834f4e1cb9c9c346210d7a775e324.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/400088_jpg.rf.eda018ddf27f1c22d7f45761b0a75798.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/400107_jpg.rf.515f55a1de9cc99c0c409ba334731d2d.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/500051_jpg.rf.e010263d0d9533b14e004e7d0fa2d518.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      6.191      11.618]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/500582_jpg.rf.2c885f30ad0bb21ea44663154df30e84.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/800140_jpg.rf.e7fbf0cc198ccf822a64e158d1025786.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/800296_jpg.rf.b261b050b62caf5b8905ab5207ec58aa.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.19       11.62]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/800296_jpg.rf.f11935209d6c47d3ea26752683ae8eb3.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [          6          12]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/800471_jpg.rf.f29cf04ec2913275af298e6b91e747a1.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.2496      11.501]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/900077_jpg.rf.cc14589cb4b2cd9a8047c8c9409e6f73.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.2343      11.531]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/AluCan39.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0469]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/AluCan48.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.002]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/AluCan55.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.013]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/AluCan87.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0339]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/beverage_cans-181_jpg.rf.94c07f03b7c6fce17d30eb60adc0396a.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/beverage_cans-181_jpg.rf.ecaffc6ad6effedba20a8c0a75bd0418.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/beverage_cans-379_jpg.rf.d589f287ed8221437b38862ec573af15.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/beverage_cans-782_jpg.rf.640cc1151be852d5f1afdcc6cc639115.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/image_png.rf.1a276c55e373ab8b9f54b8edc3ef2b1d.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.018]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/plastic_bottle-249_jpg.rf.36fd97c36d8977da282b6ae11442c8d4.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/sirma-su-pet-050-lt-80b6_jpg.rf.7daabbcea204232761d8e2c76b7b1c35.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [        6.2        11.6]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/water-bottles_jpg.rf.7f2cf644e7b419c297daade95476a192.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0048      1.0135]\n",
            "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 1266, len(boxes) = 10479. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
            "Starting training for 1 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "        1/1         0G      2.917      4.023      3.685         18        640: 100%|██████████| 621/621 [2:35:06<00:00, 14.99s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 311/311 [56:02<00:00, 10.81s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all       9931      10479       0.37     0.0175     0.0159    0.00533\n",
            "\n",
            "1 epochs completed in 3.525 hours.\n",
            "Optimizer stripped from runs/detect/train/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from runs/detect/train/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating runs/detect/train/weights/best.pt...\n",
            "Ultralytics YOLOv8.1.14 🚀 Python-3.10.12 torch-2.1.0+cu121 CPU (Intel Xeon 2.20GHz)\n",
            "YOLOv8n summary (fused): 168 layers, 3006233 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 311/311 [58:23<00:00, 11.27s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all       9931      10479      0.371     0.0168     0.0159    0.00533\n",
            "                 paper       9931       2554     0.0502     0.0129      0.018     0.0053\n",
            "                 metal       9931       3956     0.0618     0.0374     0.0199    0.00807\n",
            "               plastic       9931       3969          1          0    0.00977    0.00262\n",
            "Speed: 7.9ms preprocess, 289.6ms inference, 0.0ms loss, 3.2ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train\u001b[0m\n",
            "Ultralytics YOLOv8.1.14 🚀 Python-3.10.12 torch-2.1.0+cu121 CPU (Intel Xeon 2.20GHz)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.yaml, data=/content/gdrive/My Drive/Dataset2/config2.yaml, epochs=1, time=None, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=0, project=None, name=train2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.0, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train2\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751897  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
            "YOLOv8n summary: 225 layers, 3011433 parameters, 3011417 gradients, 8.2 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train2', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/gdrive/My Drive/Dataset2/labels.cache... 9961 images, 10 backgrounds, 30 corrupt: 100%|██████████| 9961/9961 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/000004_jpg.rf.c9a159f8264017cf3789597a0ec35c09.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.2436      11.513]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/000033_jpg.rf.81397dc4bc1a4ddf7d50ccfc136e47f3.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.2484      11.503]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/100192_jpg.rf.626f02bf792fc895def8b4f466a59a8c.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/300020_jpg.rf.011b0ac5fc15ba91ea72370ebb9deb23.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/300036_jpg.rf.354962c8183eadcbf08f1143b9fa3623.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/300063_jpg.rf.22763fea4cf264c6bea75f2ed0f5ae23.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/300070_jpg.rf.c47e7acb6abb61f3bd24449593f810d6.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/400015_jpg.rf.76bc655fb8d27c1a9d1618b56b8870c0.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/400059_jpg.rf.78d834f4e1cb9c9c346210d7a775e324.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/400088_jpg.rf.eda018ddf27f1c22d7f45761b0a75798.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/400107_jpg.rf.515f55a1de9cc99c0c409ba334731d2d.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/500051_jpg.rf.e010263d0d9533b14e004e7d0fa2d518.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      6.191      11.618]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/500582_jpg.rf.2c885f30ad0bb21ea44663154df30e84.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/800140_jpg.rf.e7fbf0cc198ccf822a64e158d1025786.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/800296_jpg.rf.b261b050b62caf5b8905ab5207ec58aa.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.19       11.62]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/800296_jpg.rf.f11935209d6c47d3ea26752683ae8eb3.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [          6          12]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/800471_jpg.rf.f29cf04ec2913275af298e6b91e747a1.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.2496      11.501]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/900077_jpg.rf.cc14589cb4b2cd9a8047c8c9409e6f73.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.2343      11.531]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/AluCan39.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0469]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/AluCan48.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.002]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/AluCan55.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.013]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/AluCan87.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0339]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/beverage_cans-181_jpg.rf.94c07f03b7c6fce17d30eb60adc0396a.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/beverage_cans-181_jpg.rf.ecaffc6ad6effedba20a8c0a75bd0418.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/beverage_cans-379_jpg.rf.d589f287ed8221437b38862ec573af15.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/beverage_cans-782_jpg.rf.640cc1151be852d5f1afdcc6cc639115.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/image_png.rf.1a276c55e373ab8b9f54b8edc3ef2b1d.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.018]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/plastic_bottle-249_jpg.rf.36fd97c36d8977da282b6ae11442c8d4.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/sirma-su-pet-050-lt-80b6_jpg.rf.7daabbcea204232761d8e2c76b7b1c35.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [        6.2        11.6]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/water-bottles_jpg.rf.7f2cf644e7b419c297daade95476a192.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0048      1.0135]\n",
            "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 1266, len(boxes) = 10479. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/gdrive/My Drive/Dataset2/labels.cache... 9961 images, 10 backgrounds, 30 corrupt: 100%|██████████| 9961/9961 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/000004_jpg.rf.c9a159f8264017cf3789597a0ec35c09.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.2436      11.513]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/000033_jpg.rf.81397dc4bc1a4ddf7d50ccfc136e47f3.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.2484      11.503]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/100192_jpg.rf.626f02bf792fc895def8b4f466a59a8c.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/300020_jpg.rf.011b0ac5fc15ba91ea72370ebb9deb23.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/300036_jpg.rf.354962c8183eadcbf08f1143b9fa3623.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/300063_jpg.rf.22763fea4cf264c6bea75f2ed0f5ae23.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/300070_jpg.rf.c47e7acb6abb61f3bd24449593f810d6.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/400015_jpg.rf.76bc655fb8d27c1a9d1618b56b8870c0.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/400059_jpg.rf.78d834f4e1cb9c9c346210d7a775e324.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/400088_jpg.rf.eda018ddf27f1c22d7f45761b0a75798.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/400107_jpg.rf.515f55a1de9cc99c0c409ba334731d2d.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/500051_jpg.rf.e010263d0d9533b14e004e7d0fa2d518.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      6.191      11.618]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/500582_jpg.rf.2c885f30ad0bb21ea44663154df30e84.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/800140_jpg.rf.e7fbf0cc198ccf822a64e158d1025786.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/800296_jpg.rf.b261b050b62caf5b8905ab5207ec58aa.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.19       11.62]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/800296_jpg.rf.f11935209d6c47d3ea26752683ae8eb3.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [          6          12]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/800471_jpg.rf.f29cf04ec2913275af298e6b91e747a1.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.2496      11.501]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/900077_jpg.rf.cc14589cb4b2cd9a8047c8c9409e6f73.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.2343      11.531]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/AluCan39.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0469]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/AluCan48.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.002]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/AluCan55.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.013]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/AluCan87.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0339]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/beverage_cans-181_jpg.rf.94c07f03b7c6fce17d30eb60adc0396a.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/beverage_cans-181_jpg.rf.ecaffc6ad6effedba20a8c0a75bd0418.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/beverage_cans-379_jpg.rf.d589f287ed8221437b38862ec573af15.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/beverage_cans-782_jpg.rf.640cc1151be852d5f1afdcc6cc639115.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/image_png.rf.1a276c55e373ab8b9f54b8edc3ef2b1d.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.018]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/plastic_bottle-249_jpg.rf.36fd97c36d8977da282b6ae11442c8d4.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/sirma-su-pet-050-lt-80b6_jpg.rf.7daabbcea204232761d8e2c76b7b1c35.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [        6.2        11.6]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/water-bottles_jpg.rf.7f2cf644e7b419c297daade95476a192.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0048      1.0135]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 1266, len(boxes) = 10479. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "Plotting labels to runs/detect/train2/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train2\u001b[0m\n",
            "Starting training for 1 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "        1/1         0G      2.917      4.023      3.685         18        640: 100%|██████████| 621/621 [2:36:35<00:00, 15.13s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 311/311 [1:02:23<00:00, 12.04s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all       9931      10479       0.37     0.0175     0.0159    0.00533\n",
            "\n",
            "1 epochs completed in 3.654 hours.\n",
            "Optimizer stripped from runs/detect/train2/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from runs/detect/train2/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating runs/detect/train2/weights/best.pt...\n",
            "Ultralytics YOLOv8.1.14 🚀 Python-3.10.12 torch-2.1.0+cu121 CPU (Intel Xeon 2.20GHz)\n",
            "YOLOv8n summary (fused): 168 layers, 3006233 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 311/311 [57:11<00:00, 11.03s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all       9931      10479      0.371     0.0168     0.0159    0.00533\n",
            "                 paper       9931       2554     0.0502     0.0129      0.018     0.0053\n",
            "                 metal       9931       3956     0.0618     0.0374     0.0199    0.00807\n",
            "               plastic       9931       3969          1          0    0.00977    0.00262\n",
            "Speed: 8.1ms preprocess, 281.0ms inference, 0.0ms loss, 3.1ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train2\u001b[0m\n",
            "New https://pypi.org/project/ultralytics/8.1.15 available 😃 Update with 'pip install -U ultralytics'\n",
            "Ultralytics YOLOv8.1.14 🚀 Python-3.10.12 torch-2.1.0+cu121 CPU (Intel Xeon 2.20GHz)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.yaml, data=/content/gdrive/My Drive/Dataset2/config2.yaml, epochs=1, time=None, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=0, project=None, name=train22, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.0, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train22\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751897  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
            "YOLOv8n summary: 225 layers, 3011433 parameters, 3011417 gradients, 8.2 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train22', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/gdrive/My Drive/Dataset2/labels.cache... 9961 images, 10 backgrounds, 30 corrupt: 100%|██████████| 9961/9961 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/000004_jpg.rf.c9a159f8264017cf3789597a0ec35c09.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.2436      11.513]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/000033_jpg.rf.81397dc4bc1a4ddf7d50ccfc136e47f3.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.2484      11.503]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/100192_jpg.rf.626f02bf792fc895def8b4f466a59a8c.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/300020_jpg.rf.011b0ac5fc15ba91ea72370ebb9deb23.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/300036_jpg.rf.354962c8183eadcbf08f1143b9fa3623.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/300063_jpg.rf.22763fea4cf264c6bea75f2ed0f5ae23.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/300070_jpg.rf.c47e7acb6abb61f3bd24449593f810d6.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/400015_jpg.rf.76bc655fb8d27c1a9d1618b56b8870c0.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/400059_jpg.rf.78d834f4e1cb9c9c346210d7a775e324.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/400088_jpg.rf.eda018ddf27f1c22d7f45761b0a75798.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/400107_jpg.rf.515f55a1de9cc99c0c409ba334731d2d.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/500051_jpg.rf.e010263d0d9533b14e004e7d0fa2d518.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      6.191      11.618]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/500582_jpg.rf.2c885f30ad0bb21ea44663154df30e84.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/800140_jpg.rf.e7fbf0cc198ccf822a64e158d1025786.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/800296_jpg.rf.b261b050b62caf5b8905ab5207ec58aa.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.19       11.62]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/800296_jpg.rf.f11935209d6c47d3ea26752683ae8eb3.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [          6          12]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/800471_jpg.rf.f29cf04ec2913275af298e6b91e747a1.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.2496      11.501]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/900077_jpg.rf.cc14589cb4b2cd9a8047c8c9409e6f73.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.2343      11.531]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/AluCan39.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0469]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/AluCan48.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.002]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/AluCan55.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.013]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/AluCan87.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0339]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/beverage_cans-181_jpg.rf.94c07f03b7c6fce17d30eb60adc0396a.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/beverage_cans-181_jpg.rf.ecaffc6ad6effedba20a8c0a75bd0418.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/beverage_cans-379_jpg.rf.d589f287ed8221437b38862ec573af15.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/beverage_cans-782_jpg.rf.640cc1151be852d5f1afdcc6cc639115.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/image_png.rf.1a276c55e373ab8b9f54b8edc3ef2b1d.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.018]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/plastic_bottle-249_jpg.rf.36fd97c36d8977da282b6ae11442c8d4.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/sirma-su-pet-050-lt-80b6_jpg.rf.7daabbcea204232761d8e2c76b7b1c35.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [        6.2        11.6]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/water-bottles_jpg.rf.7f2cf644e7b419c297daade95476a192.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0048      1.0135]\n",
            "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 1266, len(boxes) = 10479. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/gdrive/My Drive/Dataset2/labels.cache... 9961 images, 10 backgrounds, 30 corrupt: 100%|██████████| 9961/9961 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/000004_jpg.rf.c9a159f8264017cf3789597a0ec35c09.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.2436      11.513]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/000033_jpg.rf.81397dc4bc1a4ddf7d50ccfc136e47f3.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.2484      11.503]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/100192_jpg.rf.626f02bf792fc895def8b4f466a59a8c.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/300020_jpg.rf.011b0ac5fc15ba91ea72370ebb9deb23.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/300036_jpg.rf.354962c8183eadcbf08f1143b9fa3623.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/300063_jpg.rf.22763fea4cf264c6bea75f2ed0f5ae23.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/300070_jpg.rf.c47e7acb6abb61f3bd24449593f810d6.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/400015_jpg.rf.76bc655fb8d27c1a9d1618b56b8870c0.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/400059_jpg.rf.78d834f4e1cb9c9c346210d7a775e324.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/400088_jpg.rf.eda018ddf27f1c22d7f45761b0a75798.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/400107_jpg.rf.515f55a1de9cc99c0c409ba334731d2d.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/500051_jpg.rf.e010263d0d9533b14e004e7d0fa2d518.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      6.191      11.618]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/500582_jpg.rf.2c885f30ad0bb21ea44663154df30e84.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/800140_jpg.rf.e7fbf0cc198ccf822a64e158d1025786.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/800296_jpg.rf.b261b050b62caf5b8905ab5207ec58aa.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.19       11.62]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/800296_jpg.rf.f11935209d6c47d3ea26752683ae8eb3.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [          6          12]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/800471_jpg.rf.f29cf04ec2913275af298e6b91e747a1.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.2496      11.501]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/900077_jpg.rf.cc14589cb4b2cd9a8047c8c9409e6f73.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.2343      11.531]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/AluCan39.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0469]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/AluCan48.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.002]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/AluCan55.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.013]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/AluCan87.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0339]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/beverage_cans-181_jpg.rf.94c07f03b7c6fce17d30eb60adc0396a.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/beverage_cans-181_jpg.rf.ecaffc6ad6effedba20a8c0a75bd0418.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/beverage_cans-379_jpg.rf.d589f287ed8221437b38862ec573af15.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/beverage_cans-782_jpg.rf.640cc1151be852d5f1afdcc6cc639115.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/image_png.rf.1a276c55e373ab8b9f54b8edc3ef2b1d.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.018]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/plastic_bottle-249_jpg.rf.36fd97c36d8977da282b6ae11442c8d4.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/sirma-su-pet-050-lt-80b6_jpg.rf.7daabbcea204232761d8e2c76b7b1c35.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [        6.2        11.6]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/water-bottles_jpg.rf.7f2cf644e7b419c297daade95476a192.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0048      1.0135]\n",
            "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 1266, len(boxes) = 10479. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to runs/detect/train22/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train22\u001b[0m\n",
            "Starting training for 1 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "        1/1         0G      3.086      4.154      3.947         38        640:  64%|██████▍   | 398/621 [1:53:18<1:03:52, 17.19s/it]"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Define the path where you want to save the checkpoints\n",
        "checkpoint_dir = \"/content/gdrive/My Drive/checkpoints/\"\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "# Load a model\n",
        "model = YOLO(\"yolov8n.yaml\") # build a new model from scratch\n",
        "\n",
        "# Use the model\n",
        "for epoch in range(1, 11):  # Assuming you want to train for 12 epochs\n",
        "    # Train the model for one epoch\n",
        "    results = model.train(data=os.path.join(DATA_DIR, \"config2.yaml\"), epochs=1)\n",
        "\n",
        "    # Save the model checkpoint\n",
        "    checkpoint_path = os.path.join(checkpoint_dir, f\"epoch_{epoch}.pt\")\n",
        "    torch.save(model.model.state_dict(), checkpoint_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HrLVev0KrYB5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QARt4_PnLZ3E",
        "outputId": "8f861aa1-9211-4a86-e3e2-aac7242918eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ls: cannot access '/content/gdrive/My': No such file or directory\n",
            "ls: cannot access 'Drive/Dataset0/': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!ls {DATA_DIR}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuPvzd9CDJfo",
        "outputId": "d91528da-b802-44f6-94ed-c85bcf9ad3dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics YOLOv8.1.15 🚀 Python-3.10.12 torch-2.1.0+cu121 CPU (Intel Xeon 2.20GHz)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.yaml, data=/content/gdrive/My Drive/Dataset2/config2.yaml, epochs=2, time=None, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 755k/755k [00:00<00:00, 16.5MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overriding model.yaml nc=80 with nc=3\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751897  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
            "YOLOv8n summary: 225 layers, 3011433 parameters, 3011417 gradients, 8.2 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/gdrive/My Drive/Dataset2/labels.cache... 9961 images, 10 backgrounds, 30 corrupt: 100%|██████████| 9961/9961 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/000004_jpg.rf.c9a159f8264017cf3789597a0ec35c09.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.2436      11.513]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/000033_jpg.rf.81397dc4bc1a4ddf7d50ccfc136e47f3.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.2484      11.503]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/100192_jpg.rf.626f02bf792fc895def8b4f466a59a8c.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/300020_jpg.rf.011b0ac5fc15ba91ea72370ebb9deb23.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/300036_jpg.rf.354962c8183eadcbf08f1143b9fa3623.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/300063_jpg.rf.22763fea4cf264c6bea75f2ed0f5ae23.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/300070_jpg.rf.c47e7acb6abb61f3bd24449593f810d6.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/400015_jpg.rf.76bc655fb8d27c1a9d1618b56b8870c0.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/400059_jpg.rf.78d834f4e1cb9c9c346210d7a775e324.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/400088_jpg.rf.eda018ddf27f1c22d7f45761b0a75798.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/400107_jpg.rf.515f55a1de9cc99c0c409ba334731d2d.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/500051_jpg.rf.e010263d0d9533b14e004e7d0fa2d518.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      6.191      11.618]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/500582_jpg.rf.2c885f30ad0bb21ea44663154df30e84.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/800140_jpg.rf.e7fbf0cc198ccf822a64e158d1025786.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/800296_jpg.rf.b261b050b62caf5b8905ab5207ec58aa.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.19       11.62]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/800296_jpg.rf.f11935209d6c47d3ea26752683ae8eb3.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [          6          12]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/800471_jpg.rf.f29cf04ec2913275af298e6b91e747a1.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.2496      11.501]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/900077_jpg.rf.cc14589cb4b2cd9a8047c8c9409e6f73.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.2343      11.531]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/AluCan39.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0469]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/AluCan48.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.002]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/AluCan55.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.013]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/AluCan87.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0339]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/beverage_cans-181_jpg.rf.94c07f03b7c6fce17d30eb60adc0396a.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/beverage_cans-181_jpg.rf.ecaffc6ad6effedba20a8c0a75bd0418.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/beverage_cans-379_jpg.rf.d589f287ed8221437b38862ec573af15.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/beverage_cans-782_jpg.rf.640cc1151be852d5f1afdcc6cc639115.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/image_png.rf.1a276c55e373ab8b9f54b8edc3ef2b1d.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.018]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/plastic_bottle-249_jpg.rf.36fd97c36d8977da282b6ae11442c8d4.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/sirma-su-pet-050-lt-80b6_jpg.rf.7daabbcea204232761d8e2c76b7b1c35.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [        6.2        11.6]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/water-bottles_jpg.rf.7f2cf644e7b419c297daade95476a192.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0048      1.0135]\n",
            "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 1266, len(boxes) = 10479. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/gdrive/My Drive/Dataset2/labels.cache... 9961 images, 10 backgrounds, 30 corrupt: 100%|██████████| 9961/9961 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/000004_jpg.rf.c9a159f8264017cf3789597a0ec35c09.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.2436      11.513]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/000033_jpg.rf.81397dc4bc1a4ddf7d50ccfc136e47f3.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.2484      11.503]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/100192_jpg.rf.626f02bf792fc895def8b4f466a59a8c.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/300020_jpg.rf.011b0ac5fc15ba91ea72370ebb9deb23.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/300036_jpg.rf.354962c8183eadcbf08f1143b9fa3623.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/300063_jpg.rf.22763fea4cf264c6bea75f2ed0f5ae23.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/300070_jpg.rf.c47e7acb6abb61f3bd24449593f810d6.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/400015_jpg.rf.76bc655fb8d27c1a9d1618b56b8870c0.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/400059_jpg.rf.78d834f4e1cb9c9c346210d7a775e324.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/400088_jpg.rf.eda018ddf27f1c22d7f45761b0a75798.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/400107_jpg.rf.515f55a1de9cc99c0c409ba334731d2d.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/500051_jpg.rf.e010263d0d9533b14e004e7d0fa2d518.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      6.191      11.618]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/500582_jpg.rf.2c885f30ad0bb21ea44663154df30e84.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/800140_jpg.rf.e7fbf0cc198ccf822a64e158d1025786.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/800296_jpg.rf.b261b050b62caf5b8905ab5207ec58aa.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.19       11.62]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/800296_jpg.rf.f11935209d6c47d3ea26752683ae8eb3.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [          6          12]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/800471_jpg.rf.f29cf04ec2913275af298e6b91e747a1.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.2496      11.501]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/900077_jpg.rf.cc14589cb4b2cd9a8047c8c9409e6f73.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.2343      11.531]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/AluCan39.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0469]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/AluCan48.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.002]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/AluCan55.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.013]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/AluCan87.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0339]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/beverage_cans-181_jpg.rf.94c07f03b7c6fce17d30eb60adc0396a.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/beverage_cans-181_jpg.rf.ecaffc6ad6effedba20a8c0a75bd0418.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/beverage_cans-379_jpg.rf.d589f287ed8221437b38862ec573af15.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/beverage_cans-782_jpg.rf.640cc1151be852d5f1afdcc6cc639115.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/image_png.rf.1a276c55e373ab8b9f54b8edc3ef2b1d.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.018]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/plastic_bottle-249_jpg.rf.36fd97c36d8977da282b6ae11442c8d4.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/sirma-su-pet-050-lt-80b6_jpg.rf.7daabbcea204232761d8e2c76b7b1c35.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [        6.2        11.6]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/water-bottles_jpg.rf.7f2cf644e7b419c297daade95476a192.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0048      1.0135]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 1266, len(boxes) = 10479. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "Plotting labels to runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
            "Starting training for 2 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "        1/2         0G      2.917      4.023      3.685         18        640: 100%|██████████| 621/621 [3:10:57<00:00, 18.45s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 311/311 [58:54<00:00, 11.36s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all       9931      10479       0.37     0.0175     0.0159    0.00533\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "        2/2         0G       2.05       3.12       2.64         26        640: 100%|██████████| 621/621 [2:24:37<00:00, 13.97s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 311/311 [1:02:04<00:00, 11.98s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all       9931      10479      0.243      0.298      0.191     0.0951\n",
            "\n",
            "2 epochs completed in 7.612 hours.\n",
            "Optimizer stripped from runs/detect/train/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from runs/detect/train/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating runs/detect/train/weights/best.pt...\n",
            "Ultralytics YOLOv8.1.15 🚀 Python-3.10.12 torch-2.1.0+cu121 CPU (Intel Xeon 2.20GHz)\n",
            "YOLOv8n summary (fused): 168 layers, 3006233 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 311/311 [53:33<00:00, 10.33s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all       9931      10479      0.243      0.298      0.191      0.095\n",
            "                 paper       9931       2554      0.242      0.371      0.206      0.104\n",
            "                 metal       9931       3956       0.33      0.439      0.315      0.159\n",
            "               plastic       9931       3969      0.155     0.0839     0.0524     0.0216\n",
            "Speed: 7.2ms preprocess, 263.6ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "from ultralytics import YOLO\n",
        "\n",
        "\n",
        "# Load a model\n",
        "model = YOLO(\"yolov8n.yaml\") # build a new model from scratch\n",
        "\n",
        "# Use the model\n",
        "results = model.train(data=os.path.join(DATA_DIR, \"config2.yaml\"), epochs=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "haXVvdQ1rZf5"
      },
      "outputs": [],
      "source": [
        "!scp -r /content/runs '/content/gdrive/My Drive/Dataset2'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GL-f0dmo4qzw",
        "outputId": "8c04af85-0c09-4ff6-8c3d-bda0d87e8cd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics YOLOv8.1.15 🚀 Python-3.10.12 torch-2.1.0+cu121 CPU (Intel Xeon 2.20GHz)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=/content/gdrive/My Drive/Dataset2/runs/detect/train/weights/last.pt, data=/content/gdrive/My Drive/Dataset2/config2.yaml, epochs=2, time=None, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 755k/755k [00:00<00:00, 15.8MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751897  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
            "YOLOv8n summary: 225 layers, 3011433 parameters, 3011417 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 355/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/gdrive/My Drive/Dataset2/labels.cache... 9961 images, 10 backgrounds, 30 corrupt: 100%|██████████| 9961/9961 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/000004_jpg.rf.c9a159f8264017cf3789597a0ec35c09.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.2436      11.513]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/000033_jpg.rf.81397dc4bc1a4ddf7d50ccfc136e47f3.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.2484      11.503]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/100192_jpg.rf.626f02bf792fc895def8b4f466a59a8c.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/300020_jpg.rf.011b0ac5fc15ba91ea72370ebb9deb23.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/300036_jpg.rf.354962c8183eadcbf08f1143b9fa3623.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/300063_jpg.rf.22763fea4cf264c6bea75f2ed0f5ae23.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/300070_jpg.rf.c47e7acb6abb61f3bd24449593f810d6.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/400015_jpg.rf.76bc655fb8d27c1a9d1618b56b8870c0.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/400059_jpg.rf.78d834f4e1cb9c9c346210d7a775e324.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/400088_jpg.rf.eda018ddf27f1c22d7f45761b0a75798.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/400107_jpg.rf.515f55a1de9cc99c0c409ba334731d2d.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/500051_jpg.rf.e010263d0d9533b14e004e7d0fa2d518.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      6.191      11.618]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/500582_jpg.rf.2c885f30ad0bb21ea44663154df30e84.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/800140_jpg.rf.e7fbf0cc198ccf822a64e158d1025786.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/800296_jpg.rf.b261b050b62caf5b8905ab5207ec58aa.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.19       11.62]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/800296_jpg.rf.f11935209d6c47d3ea26752683ae8eb3.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [          6          12]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/800471_jpg.rf.f29cf04ec2913275af298e6b91e747a1.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.2496      11.501]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/900077_jpg.rf.cc14589cb4b2cd9a8047c8c9409e6f73.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.2343      11.531]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/AluCan39.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0469]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/AluCan48.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.002]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/AluCan55.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.013]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/AluCan87.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0339]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/beverage_cans-181_jpg.rf.94c07f03b7c6fce17d30eb60adc0396a.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/beverage_cans-181_jpg.rf.ecaffc6ad6effedba20a8c0a75bd0418.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/beverage_cans-379_jpg.rf.d589f287ed8221437b38862ec573af15.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/beverage_cans-782_jpg.rf.640cc1151be852d5f1afdcc6cc639115.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/image_png.rf.1a276c55e373ab8b9f54b8edc3ef2b1d.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.018]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/plastic_bottle-249_jpg.rf.36fd97c36d8977da282b6ae11442c8d4.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/sirma-su-pet-050-lt-80b6_jpg.rf.7daabbcea204232761d8e2c76b7b1c35.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [        6.2        11.6]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/water-bottles_jpg.rf.7f2cf644e7b419c297daade95476a192.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0048      1.0135]\n",
            "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 1266, len(boxes) = 10479. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/gdrive/My Drive/Dataset2/labels.cache... 9961 images, 10 backgrounds, 30 corrupt: 100%|██████████| 9961/9961 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/000004_jpg.rf.c9a159f8264017cf3789597a0ec35c09.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.2436      11.513]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/000033_jpg.rf.81397dc4bc1a4ddf7d50ccfc136e47f3.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.2484      11.503]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/100192_jpg.rf.626f02bf792fc895def8b4f466a59a8c.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/300020_jpg.rf.011b0ac5fc15ba91ea72370ebb9deb23.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/300036_jpg.rf.354962c8183eadcbf08f1143b9fa3623.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/300063_jpg.rf.22763fea4cf264c6bea75f2ed0f5ae23.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/300070_jpg.rf.c47e7acb6abb61f3bd24449593f810d6.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/400015_jpg.rf.76bc655fb8d27c1a9d1618b56b8870c0.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/400059_jpg.rf.78d834f4e1cb9c9c346210d7a775e324.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/400088_jpg.rf.eda018ddf27f1c22d7f45761b0a75798.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/400107_jpg.rf.515f55a1de9cc99c0c409ba334731d2d.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/500051_jpg.rf.e010263d0d9533b14e004e7d0fa2d518.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      6.191      11.618]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/500582_jpg.rf.2c885f30ad0bb21ea44663154df30e84.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/800140_jpg.rf.e7fbf0cc198ccf822a64e158d1025786.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/800296_jpg.rf.b261b050b62caf5b8905ab5207ec58aa.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.19       11.62]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/800296_jpg.rf.f11935209d6c47d3ea26752683ae8eb3.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [          6          12]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/800471_jpg.rf.f29cf04ec2913275af298e6b91e747a1.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.2496      11.501]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/900077_jpg.rf.cc14589cb4b2cd9a8047c8c9409e6f73.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.2343      11.531]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/AluCan39.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0469]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/AluCan48.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.002]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/AluCan55.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.013]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/AluCan87.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0339]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/beverage_cans-181_jpg.rf.94c07f03b7c6fce17d30eb60adc0396a.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/beverage_cans-181_jpg.rf.ecaffc6ad6effedba20a8c0a75bd0418.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/beverage_cans-379_jpg.rf.d589f287ed8221437b38862ec573af15.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/beverage_cans-782_jpg.rf.640cc1151be852d5f1afdcc6cc639115.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/image_png.rf.1a276c55e373ab8b9f54b8edc3ef2b1d.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.018]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/plastic_bottle-249_jpg.rf.36fd97c36d8977da282b6ae11442c8d4.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/sirma-su-pet-050-lt-80b6_jpg.rf.7daabbcea204232761d8e2c76b7b1c35.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [        6.2        11.6]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/water-bottles_jpg.rf.7f2cf644e7b419c297daade95476a192.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0048      1.0135]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 1266, len(boxes) = 10479. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "Plotting labels to runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
            "Starting training for 2 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "        1/2         0G      1.735      2.566       2.32         18        640: 100%|██████████| 621/621 [3:06:58<00:00, 18.06s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 311/311 [51:21<00:00,  9.91s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all       9931      10479      0.456      0.368      0.348      0.205\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "        2/2         0G      1.584      2.275      2.157         26        640: 100%|██████████| 621/621 [2:24:01<00:00, 13.92s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 311/311 [1:01:12<00:00, 11.81s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all       9931      10479      0.532      0.453      0.443      0.279\n",
            "\n",
            "2 epochs completed in 7.395 hours.\n",
            "Optimizer stripped from runs/detect/train/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from runs/detect/train/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating runs/detect/train/weights/best.pt...\n",
            "Ultralytics YOLOv8.1.15 🚀 Python-3.10.12 torch-2.1.0+cu121 CPU (Intel Xeon 2.20GHz)\n",
            "YOLOv8n summary (fused): 168 layers, 3006233 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 311/311 [51:04<00:00,  9.85s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all       9931      10479      0.532      0.453      0.443      0.279\n",
            "                 paper       9931       2554      0.692      0.439      0.516      0.336\n",
            "                 metal       9931       3956      0.582       0.64       0.61      0.388\n",
            "               plastic       9931       3969      0.321       0.28      0.204      0.113\n",
            "Speed: 7.0ms preprocess, 251.8ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from ultralytics import YOLO\n",
        "import torch\n",
        "\n",
        "# Load a model\n",
        "model = YOLO(\"/content/gdrive/My Drive/Dataset2/runs/detect/train/weights/last.pt\")   # Initialize a new model instance with the correct architecture configuration file\n",
        "\n",
        "\n",
        "# Define the number of epochs to train\n",
        "additional_epochs = 2\n",
        "\n",
        "# Use the model for training\n",
        "results = model.train(data=os.path.join(DATA_DIR, \"config2.yaml\"), epochs=additional_epochs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vhhe5QN0jNSN"
      },
      "outputs": [],
      "source": [
        "!scp -r /content/runs '/content/gdrive/My Drive/Dataset2'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skqgg1b2tUqO",
        "outputId": "c31e7c36-0419-4c16-f923-d02ed3d6ac50"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics YOLOv8.1.16 🚀 Python-3.10.12 torch-2.1.0+cu121 CPU (Intel Xeon 2.20GHz)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=/content/gdrive/My Drive/Dataset2/runs/detect/train/weights/last.pt, data=/content/gdrive/My Drive/Dataset2/config2.yaml, epochs=2, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 755k/755k [00:00<00:00, 18.0MB/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751897  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
            "YOLOv8n summary: 225 layers, 3011433 parameters, 3011417 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 355/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/gdrive/My Drive/Dataset2/labels.cache... 9961 images, 10 backgrounds, 30 corrupt: 100%|██████████| 9961/9961 [00:00<?, ?it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/000004_jpg.rf.c9a159f8264017cf3789597a0ec35c09.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.2436      11.513]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/000033_jpg.rf.81397dc4bc1a4ddf7d50ccfc136e47f3.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.2484      11.503]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/100192_jpg.rf.626f02bf792fc895def8b4f466a59a8c.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/300020_jpg.rf.011b0ac5fc15ba91ea72370ebb9deb23.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/300036_jpg.rf.354962c8183eadcbf08f1143b9fa3623.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/300063_jpg.rf.22763fea4cf264c6bea75f2ed0f5ae23.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/300070_jpg.rf.c47e7acb6abb61f3bd24449593f810d6.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/400015_jpg.rf.76bc655fb8d27c1a9d1618b56b8870c0.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/400059_jpg.rf.78d834f4e1cb9c9c346210d7a775e324.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/400088_jpg.rf.eda018ddf27f1c22d7f45761b0a75798.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/400107_jpg.rf.515f55a1de9cc99c0c409ba334731d2d.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/500051_jpg.rf.e010263d0d9533b14e004e7d0fa2d518.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      6.191      11.618]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/500582_jpg.rf.2c885f30ad0bb21ea44663154df30e84.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/800140_jpg.rf.e7fbf0cc198ccf822a64e158d1025786.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/800296_jpg.rf.b261b050b62caf5b8905ab5207ec58aa.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.19       11.62]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/800296_jpg.rf.f11935209d6c47d3ea26752683ae8eb3.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [          6          12]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/800471_jpg.rf.f29cf04ec2913275af298e6b91e747a1.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.2496      11.501]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/900077_jpg.rf.cc14589cb4b2cd9a8047c8c9409e6f73.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.2343      11.531]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/AluCan39.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0469]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/AluCan48.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.002]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/AluCan55.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.013]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/AluCan87.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0339]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/beverage_cans-181_jpg.rf.94c07f03b7c6fce17d30eb60adc0396a.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/beverage_cans-181_jpg.rf.ecaffc6ad6effedba20a8c0a75bd0418.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/beverage_cans-379_jpg.rf.d589f287ed8221437b38862ec573af15.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/beverage_cans-782_jpg.rf.640cc1151be852d5f1afdcc6cc639115.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/image_png.rf.1a276c55e373ab8b9f54b8edc3ef2b1d.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.018]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/plastic_bottle-249_jpg.rf.36fd97c36d8977da282b6ae11442c8d4.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/sirma-su-pet-050-lt-80b6_jpg.rf.7daabbcea204232761d8e2c76b7b1c35.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [        6.2        11.6]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/water-bottles_jpg.rf.7f2cf644e7b419c297daade95476a192.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0048      1.0135]\n",
            "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 1266, len(boxes) = 10479. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/gdrive/My Drive/Dataset2/labels.cache... 9961 images, 10 backgrounds, 30 corrupt: 100%|██████████| 9961/9961 [00:00<?, ?it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/000004_jpg.rf.c9a159f8264017cf3789597a0ec35c09.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.2436      11.513]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/000033_jpg.rf.81397dc4bc1a4ddf7d50ccfc136e47f3.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.2484      11.503]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/100192_jpg.rf.626f02bf792fc895def8b4f466a59a8c.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/300020_jpg.rf.011b0ac5fc15ba91ea72370ebb9deb23.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/300036_jpg.rf.354962c8183eadcbf08f1143b9fa3623.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/300063_jpg.rf.22763fea4cf264c6bea75f2ed0f5ae23.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/300070_jpg.rf.c47e7acb6abb61f3bd24449593f810d6.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/400015_jpg.rf.76bc655fb8d27c1a9d1618b56b8870c0.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/400059_jpg.rf.78d834f4e1cb9c9c346210d7a775e324.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/400088_jpg.rf.eda018ddf27f1c22d7f45761b0a75798.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/400107_jpg.rf.515f55a1de9cc99c0c409ba334731d2d.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/500051_jpg.rf.e010263d0d9533b14e004e7d0fa2d518.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      6.191      11.618]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/500582_jpg.rf.2c885f30ad0bb21ea44663154df30e84.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/800140_jpg.rf.e7fbf0cc198ccf822a64e158d1025786.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/800296_jpg.rf.b261b050b62caf5b8905ab5207ec58aa.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.19       11.62]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/800296_jpg.rf.f11935209d6c47d3ea26752683ae8eb3.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [          6          12]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/800471_jpg.rf.f29cf04ec2913275af298e6b91e747a1.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.2496      11.501]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/900077_jpg.rf.cc14589cb4b2cd9a8047c8c9409e6f73.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.2343      11.531]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/AluCan39.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0469]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/AluCan48.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.002]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/AluCan55.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.013]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/AluCan87.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0339]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/beverage_cans-181_jpg.rf.94c07f03b7c6fce17d30eb60adc0396a.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/beverage_cans-181_jpg.rf.ecaffc6ad6effedba20a8c0a75bd0418.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/beverage_cans-379_jpg.rf.d589f287ed8221437b38862ec573af15.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/beverage_cans-782_jpg.rf.640cc1151be852d5f1afdcc6cc639115.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/image_png.rf.1a276c55e373ab8b9f54b8edc3ef2b1d.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.018]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/plastic_bottle-249_jpg.rf.36fd97c36d8977da282b6ae11442c8d4.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/sirma-su-pet-050-lt-80b6_jpg.rf.7daabbcea204232761d8e2c76b7b1c35.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [        6.2        11.6]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/water-bottles_jpg.rf.7f2cf644e7b419c297daade95476a192.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0048      1.0135]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 1266, len(boxes) = 10479. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "Plotting labels to runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
            "Starting training for 2 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "        1/2         0G      1.487      2.107      2.054         18        640: 100%|██████████| 621/621 [3:15:16<00:00, 18.87s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 311/311 [49:52<00:00,  9.62s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all       9931      10479      0.535       0.45      0.458      0.295\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "        2/2         0G      1.416      1.975      1.978         26        640: 100%|██████████| 621/621 [2:31:06<00:00, 14.60s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 311/311 [48:42<00:00,  9.40s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all       9931      10479      0.611      0.514      0.525      0.353\n",
            "\n",
            "2 epochs completed in 7.418 hours.\n",
            "Optimizer stripped from runs/detect/train/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from runs/detect/train/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating runs/detect/train/weights/best.pt...\n",
            "Ultralytics YOLOv8.1.16 🚀 Python-3.10.12 torch-2.1.0+cu121 CPU (Intel Xeon 2.20GHz)\n",
            "YOLOv8n summary (fused): 168 layers, 3006233 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 311/311 [44:24<00:00,  8.57s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       9931      10479      0.611      0.514      0.525      0.353\n",
            "                 paper       9931       2554      0.702      0.528      0.598      0.425\n",
            "                 metal       9931       3956      0.676      0.724      0.712       0.48\n",
            "               plastic       9931       3969      0.454      0.289      0.264      0.155\n",
            "Speed: 2.1ms preprocess, 214.7ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from ultralytics import YOLO\n",
        "import torch\n",
        "\n",
        "# Load a model\n",
        "model = YOLO(\"/content/gdrive/My Drive/Dataset2/runs/detect/train/weights/last.pt\")   # Initialize a new model instance with the correct architecture configuration file\n",
        "\n",
        "\n",
        "# Define the number of epochs to train\n",
        "additional_epochs = 2\n",
        "\n",
        "# Use the model for training\n",
        "results = model.train(data=os.path.join(DATA_DIR, \"config2.yaml\"), epochs=additional_epochs)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!scp -r /content/runs '/content/gdrive/My Drive/Dataset2'"
      ],
      "metadata": {
        "id": "PgC2UyOLesWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from ultralytics import YOLO\n",
        "import torch\n",
        "\n",
        "# Load a model\n",
        "model = YOLO(\"/content/gdrive/My Drive/Dataset2/runs/detect/train/weights/last.pt\")   # Initialize a new model instance with the correct architecture configuration file\n",
        "\n",
        "\n",
        "# Define the number of epochs to train\n",
        "additional_epochs = 1\n",
        "\n",
        "# Use the model for training\n",
        "results = model.train(data=os.path.join(DATA_DIR, \"config2.yaml\"), epochs=additional_epochs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9ezdvUiKKJo",
        "outputId": "f83bf451-a51c-4f9a-f579-b6d33cbc8b10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.1.16 🚀 Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (NVIDIA A100-SXM4-40GB, 40514MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=/content/gdrive/My Drive/Dataset2/runs/detect/train/weights/last.pt, data=/content/gdrive/My Drive/Dataset2/config2.yaml, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 755k/755k [00:00<00:00, 155MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751897  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
            "YOLOv8n summary: 225 layers, 3011433 parameters, 3011417 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 355/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8n.pt to 'yolov8n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6.23M/6.23M [00:00<00:00, 272MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/gdrive/My Drive/Dataset2/labels.cache... 9961 images, 10 backgrounds, 30 corrupt: 100%|██████████| 9961/9961 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/000004_jpg.rf.c9a159f8264017cf3789597a0ec35c09.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.2436      11.513]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/000033_jpg.rf.81397dc4bc1a4ddf7d50ccfc136e47f3.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.2484      11.503]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/100192_jpg.rf.626f02bf792fc895def8b4f466a59a8c.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/300020_jpg.rf.011b0ac5fc15ba91ea72370ebb9deb23.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/300036_jpg.rf.354962c8183eadcbf08f1143b9fa3623.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/300063_jpg.rf.22763fea4cf264c6bea75f2ed0f5ae23.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/300070_jpg.rf.c47e7acb6abb61f3bd24449593f810d6.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/400015_jpg.rf.76bc655fb8d27c1a9d1618b56b8870c0.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/400059_jpg.rf.78d834f4e1cb9c9c346210d7a775e324.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/400088_jpg.rf.eda018ddf27f1c22d7f45761b0a75798.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/400107_jpg.rf.515f55a1de9cc99c0c409ba334731d2d.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/500051_jpg.rf.e010263d0d9533b14e004e7d0fa2d518.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      6.191      11.618]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/500582_jpg.rf.2c885f30ad0bb21ea44663154df30e84.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/800140_jpg.rf.e7fbf0cc198ccf822a64e158d1025786.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/800296_jpg.rf.b261b050b62caf5b8905ab5207ec58aa.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.19       11.62]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/800296_jpg.rf.f11935209d6c47d3ea26752683ae8eb3.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [          6          12]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/800471_jpg.rf.f29cf04ec2913275af298e6b91e747a1.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.2496      11.501]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/900077_jpg.rf.cc14589cb4b2cd9a8047c8c9409e6f73.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.2343      11.531]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/AluCan39.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0469]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/AluCan48.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.002]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/AluCan55.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.013]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/AluCan87.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0339]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/beverage_cans-181_jpg.rf.94c07f03b7c6fce17d30eb60adc0396a.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/beverage_cans-181_jpg.rf.ecaffc6ad6effedba20a8c0a75bd0418.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/beverage_cans-379_jpg.rf.d589f287ed8221437b38862ec573af15.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/beverage_cans-782_jpg.rf.640cc1151be852d5f1afdcc6cc639115.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/image_png.rf.1a276c55e373ab8b9f54b8edc3ef2b1d.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.018]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/plastic_bottle-249_jpg.rf.36fd97c36d8977da282b6ae11442c8d4.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/sirma-su-pet-050-lt-80b6_jpg.rf.7daabbcea204232761d8e2c76b7b1c35.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [        6.2        11.6]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/water-bottles_jpg.rf.7f2cf644e7b419c297daade95476a192.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0048      1.0135]\n",
            "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 1266, len(boxes) = 10479. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/gdrive/My Drive/Dataset2/labels.cache... 9961 images, 10 backgrounds, 30 corrupt: 100%|██████████| 9961/9961 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/000004_jpg.rf.c9a159f8264017cf3789597a0ec35c09.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.2436      11.513]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/000033_jpg.rf.81397dc4bc1a4ddf7d50ccfc136e47f3.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.2484      11.503]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/100192_jpg.rf.626f02bf792fc895def8b4f466a59a8c.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/300020_jpg.rf.011b0ac5fc15ba91ea72370ebb9deb23.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/300036_jpg.rf.354962c8183eadcbf08f1143b9fa3623.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/300063_jpg.rf.22763fea4cf264c6bea75f2ed0f5ae23.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/300070_jpg.rf.c47e7acb6abb61f3bd24449593f810d6.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/400015_jpg.rf.76bc655fb8d27c1a9d1618b56b8870c0.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/400059_jpg.rf.78d834f4e1cb9c9c346210d7a775e324.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/400088_jpg.rf.eda018ddf27f1c22d7f45761b0a75798.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/400107_jpg.rf.515f55a1de9cc99c0c409ba334731d2d.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/500051_jpg.rf.e010263d0d9533b14e004e7d0fa2d518.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      6.191      11.618]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/500582_jpg.rf.2c885f30ad0bb21ea44663154df30e84.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/800140_jpg.rf.e7fbf0cc198ccf822a64e158d1025786.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/800296_jpg.rf.b261b050b62caf5b8905ab5207ec58aa.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.19       11.62]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/800296_jpg.rf.f11935209d6c47d3ea26752683ae8eb3.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [          6          12]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/800471_jpg.rf.f29cf04ec2913275af298e6b91e747a1.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.2496      11.501]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/900077_jpg.rf.cc14589cb4b2cd9a8047c8c9409e6f73.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     6.2343      11.531]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/AluCan39.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0469]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/AluCan48.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.002]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/AluCan55.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.013]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/AluCan87.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0339]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/beverage_cans-181_jpg.rf.94c07f03b7c6fce17d30eb60adc0396a.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/beverage_cans-181_jpg.rf.ecaffc6ad6effedba20a8c0a75bd0418.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/beverage_cans-379_jpg.rf.d589f287ed8221437b38862ec573af15.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/beverage_cans-782_jpg.rf.640cc1151be852d5f1afdcc6cc639115.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       5.75        10.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/image_png.rf.1a276c55e373ab8b9f54b8edc3ef2b1d.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.018]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/plastic_bottle-249_jpg.rf.36fd97c36d8977da282b6ae11442c8d4.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       6.25        11.5]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/sirma-su-pet-050-lt-80b6_jpg.rf.7daabbcea204232761d8e2c76b7b1c35.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [        6.2        11.6]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/gdrive/My Drive/Dataset2/images/water-bottles_jpg.rf.7f2cf644e7b419c297daade95476a192.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0048      1.0135]\n",
            "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 1266, len(boxes) = 10479. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
            "Starting training for 1 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        1/1       2.4G      1.402      1.911      1.951         34        640: 100%|██████████| 621/621 [08:33<00:00,  1.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 311/311 [01:23<00:00,  3.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       9931      10479       0.65      0.523      0.562      0.386\n",
            "\n",
            "1 epochs completed in 0.168 hours.\n",
            "Optimizer stripped from runs/detect/train/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from runs/detect/train/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating runs/detect/train/weights/best.pt...\n",
            "Ultralytics YOLOv8.1.16 🚀 Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (NVIDIA A100-SXM4-40GB, 40514MiB)\n",
            "YOLOv8n summary (fused): 168 layers, 3006233 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 311/311 [01:16<00:00,  4.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       9931      10479       0.65      0.523      0.562      0.386\n",
            "                 paper       9931       2554      0.652      0.664      0.682      0.492\n",
            "                 metal       9931       3956      0.679      0.736      0.737      0.514\n",
            "               plastic       9931       3969      0.618       0.17      0.268      0.152\n",
            "Speed: 0.1ms preprocess, 0.6ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!scp -r /content/runs '/content/gdrive/My Drive/Dataset2'"
      ],
      "metadata": {
        "id": "i8j6-A5kNrGu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8UeUlxAuq4ot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PngK4GBuq6v0"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}